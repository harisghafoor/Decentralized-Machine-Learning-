{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t1ns5Ecy8IY"
      },
      "source": [
        "# Keras 101: A simple Neural Network for House Pricing regression\n",
        "\n",
        "\n",
        "In this post, we will be covering some basics of data exploration and building a model with Keras in order to help us on predicting the selling price of a given house in the Boston (MA) area. As an application of this model in the real world, you can think about being a real state agent looking for a tool to help you on your day-to-day duties, which for me, at least, sounds pretty good when compared to just gut-estimation.\n",
        "\n",
        "For this exercise, we will be using the [Plotly](https://plot.ly/python/) library instead of the good ol' fashioned matplotlib, due to having more interactive plots, which for sure help in understanding the data. We will also use the [Scikit-Learn](https://scikit-learn.org/stable/) and [Keras](https://keras.io/) for building the models, [Pandas](https://pandas.pydata.org/) library to manipulate our data and the [SHAP library](https://github.com/slundberg/shap) to generate explanations for our trained model.\n",
        "\n",
        "### Importing the dataset\n",
        "\n",
        "In this example, we wil be using the sklearn.datasets module, which contains the Boston dataset. You could also use the keras.datasets module, but this one does not contain the labels of the features, so we decided to use scikits one. Let's also convert it to a Pandas DataFrame and print it's head.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "R5LxkIxFy8Ii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13575d11-8698-42a4-d22b-1a5059780a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
              "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
              "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
              "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
              "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
              "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  MEDV  \n",
              "0     15.3  396.90   4.98  24.0  \n",
              "1     17.8  396.90   9.14  21.6  \n",
              "2     17.8  392.83   4.03  34.7  \n",
              "3     18.7  394.63   2.94  33.4  \n",
              "4     18.7  396.90   5.33  36.2  \n",
              "5     18.7  394.12   5.21  28.7  \n",
              "6     15.2  395.60  12.43  22.9  \n",
              "7     15.2  396.90  19.15  27.1  \n",
              "8     15.2  386.63  29.93  16.5  \n",
              "9     15.2  386.71  17.10  18.9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d0d64f5-7af9-4757-9d4c-b92395b363b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d0d64f5-7af9-4757-9d4c-b92395b363b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d0d64f5-7af9-4757-9d4c-b92395b363b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d0d64f5-7af9-4757-9d4c-b92395b363b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "\n",
        "boston_dataset = load_boston()\n",
        "\n",
        "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
        "df['MEDV'] = boston_dataset.target\n",
        "df = df.iloc[:250,:]\n",
        "df.head(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On8p6XM9y8Il"
      },
      "source": [
        "\n",
        "### Exploratory Data Analysis\n",
        "\n",
        "Making yourself comfortable and familiar with your dataset is a fundamental step to help you comprehend your data and draw better conclusions and explanations from your results.\n",
        "\n",
        "Initially, let's plot a few box plots, which will help us to better visualizate anomalies and/or outliers in data distribution. If you are confused about what is a box plot and how it can help us to better visualizate the distribution of our data, here is a brief description from Ross (1977):\n",
        "\n",
        "> In descriptive statistics, a box plot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram. Outliers may be plotted as individual points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WTkCr-YAy8Il",
        "outputId": "fceadd03-5878-4239-8f59-25b35378db78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"337044ea-b7f6-48e3-bfd4-6418fd042d52\" class=\"plotly-graph-div\" style=\"height:1000px; width:550px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"337044ea-b7f6-48e3-bfd4-6418fd042d52\")) {                    Plotly.newPlot(                        \"337044ea-b7f6-48e3-bfd4-6418fd042d52\",                        [{\"name\":\"CRIM\",\"y\":[0.00632,0.02731,0.02729,0.03237,0.06905,0.02985,0.08829,0.14455,0.21124,0.17004,0.22489,0.11747,0.09378,0.62976,0.63796,0.62739,1.05393,0.7842,0.80271,0.7258,1.25179,0.85204,1.23247,0.98843,0.75026,0.84054,0.67191,0.95577,0.77299,1.00245,1.13081,1.35472,1.38799,1.15172,1.61282,0.06417,0.09744,0.08014,0.17505,0.02763,0.03359,0.12744,0.1415,0.15936,0.12269,0.17142,0.18836,0.22927,0.25387,0.21977,0.08873,0.04337,0.0536,0.04981,0.0136,0.01311,0.02055,0.01432,0.15445,0.10328,0.14932,0.17171,0.11027,0.1265,0.01951,0.03584,0.04379,0.05789,0.13554,0.12816,0.08826,0.15876,0.09164,0.19539,0.07896,0.09512,0.10153,0.08707,0.05646,0.08387,0.04113,0.04462,0.03659,0.03551,0.05059,0.05735,0.05188,0.07151,0.0566,0.05302,0.04684,0.03932,0.04203,0.02875,0.04294,0.12204,0.11504,0.12083,0.08187,0.0686,0.14866,0.11432,0.22876,0.21161,0.1396,0.13262,0.1712,0.13117,0.12802,0.26363,0.10793,0.10084,0.12329,0.22212,0.14231,0.17134,0.13158,0.15098,0.13058,0.14476,0.06899,0.07165,0.09299,0.15038,0.09849,0.16902,0.38735,0.25915,0.32543,0.88125,0.34006,1.19294,0.59005,0.32982,0.97617,0.55778,0.32264,0.35233,0.2498,0.54452,0.2909,1.62864,3.32105,4.0974,2.77974,2.37934,2.15505,2.36862,2.33099,2.73397,1.6566,1.49632,1.12658,2.14918,1.41385,3.53501,2.44668,1.22358,1.34284,1.42502,1.27346,1.46336,1.83377,1.51902,2.24236,2.924,2.01019,1.80028,2.3004,2.44953,1.20742,2.3139,0.13914,0.09178,0.08447,0.06664,0.07022,0.05425,0.06642,0.0578,0.06588,0.06888,0.09103,0.10008,0.08308,0.06047,0.05602,0.07875,0.12579,0.0837,0.09068,0.06911,0.08664,0.02187,0.01439,0.01381,0.04011,0.04666,0.03768,0.0315,0.01778,0.03445,0.02177,0.0351,0.02009,0.13642,0.22969,0.25199,0.13587,0.43571,0.17446,0.37578,0.21719,0.14052,0.28955,0.19802,0.0456,0.07013,0.11069,0.11425,0.35809,0.40771,0.62356,0.6147,0.31533,0.52693,0.38214,0.41238,0.29819,0.44178,0.537,0.46296,0.57529,0.33147,0.44791,0.33045,0.52058,0.51183,0.08244,0.09252,0.11329,0.10612,0.1029,0.12757,0.20608,0.19133,0.33983,0.19657,0.16439,0.19073],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"ZN\",\"y\":[18.0,0.0,0.0,0.0,0.0,0.0,12.5,12.5,12.5,12.5,12.5,12.5,12.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,75.0,75.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,21.0,21.0,21.0,21.0,75.0,90.0,85.0,100.0,25.0,25.0,25.0,25.0,25.0,25.0,17.5,80.0,80.0,12.5,12.5,12.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,25.0,25.0,25.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,28.0,28.0,28.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,45.0,45.0,45.0,45.0,45.0,45.0,60.0,60.0,80.0,80.0,80.0,80.0,95.0,95.0,82.5,82.5,95.0,95.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,30.0,30.0,30.0,30.0,30.0,30.0,22.0,22.0,22.0,22.0,22.0,22.0],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"INDUS\",\"y\":[2.31,7.07,7.07,2.18,2.18,2.18,7.87,7.87,7.87,7.87,7.87,7.87,7.87,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,5.96,5.96,5.96,5.96,2.95,2.95,6.91,6.91,6.91,6.91,6.91,6.91,6.91,6.91,6.91,5.64,5.64,5.64,5.64,4.0,1.22,0.74,1.32,5.13,5.13,5.13,5.13,5.13,5.13,1.38,3.37,3.37,6.07,6.07,6.07,10.81,10.81,10.81,10.81,12.83,12.83,12.83,12.83,12.83,12.83,4.86,4.86,4.86,4.86,4.49,4.49,4.49,4.49,3.41,3.41,3.41,3.41,15.04,15.04,15.04,2.89,2.89,2.89,2.89,2.89,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,10.01,10.01,10.01,10.01,10.01,10.01,10.01,10.01,10.01,25.65,25.65,25.65,25.65,25.65,25.65,25.65,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,4.05,4.05,4.05,4.05,4.05,4.05,4.05,2.46,2.46,2.46,2.46,2.46,2.46,2.46,2.46,3.44,3.44,3.44,3.44,3.44,3.44,2.93,2.93,0.46,1.52,1.52,1.52,1.47,1.47,2.03,2.03,2.68,2.68,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,13.89,13.89,13.89,13.89,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,4.93,4.93,4.93,4.93,4.93,4.93,5.86,5.86,5.86,5.86,5.86,5.86],\"type\":\"box\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"CHAS\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"box\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"NOX\",\"y\":[0.538,0.469,0.469,0.458,0.458,0.458,0.524,0.524,0.524,0.524,0.524,0.524,0.524,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.499,0.499,0.499,0.499,0.428,0.428,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.439,0.439,0.439,0.439,0.41,0.403,0.41,0.411,0.453,0.453,0.453,0.453,0.453,0.453,0.4161,0.398,0.398,0.409,0.409,0.409,0.413,0.413,0.413,0.413,0.437,0.437,0.437,0.437,0.437,0.437,0.426,0.426,0.426,0.426,0.449,0.449,0.449,0.449,0.489,0.489,0.489,0.489,0.464,0.464,0.464,0.445,0.445,0.445,0.445,0.445,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.581,0.581,0.581,0.581,0.581,0.581,0.581,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.605,0.605,0.871,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.488,0.488,0.488,0.488,0.488,0.488,0.488,0.488,0.437,0.437,0.437,0.437,0.437,0.437,0.401,0.401,0.422,0.404,0.404,0.404,0.403,0.403,0.415,0.415,0.4161,0.4161,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.55,0.55,0.55,0.55,0.507,0.507,0.507,0.507,0.504,0.504,0.504,0.504,0.504,0.504,0.504,0.504,0.507,0.507,0.507,0.507,0.507,0.507,0.428,0.428,0.428,0.428,0.428,0.428,0.431,0.431,0.431,0.431,0.431,0.431],\"type\":\"box\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"name\":\"RM\",\"y\":[6.575,6.421,7.185,6.998,7.147,6.43,6.012,6.172,5.631,6.004,6.377,6.009,5.889,5.949,6.096,5.834,5.935,5.99,5.456,5.727,5.57,5.965,6.142,5.813,5.924,5.599,5.813,6.047,6.495,6.674,5.713,6.072,5.95,5.701,6.096,5.933,5.841,5.85,5.966,6.595,7.024,6.77,6.169,6.211,6.069,5.682,5.786,6.03,5.399,5.602,5.963,6.115,6.511,5.998,5.888,7.249,6.383,6.816,6.145,5.927,5.741,5.966,6.456,6.762,7.104,6.29,5.787,5.878,5.594,5.885,6.417,5.961,6.065,6.245,6.273,6.286,6.279,6.14,6.232,5.874,6.727,6.619,6.302,6.167,6.389,6.63,6.015,6.121,7.007,7.079,6.417,6.405,6.442,6.211,6.249,6.625,6.163,8.069,7.82,7.416,6.727,6.781,6.405,6.137,6.167,5.851,5.836,6.127,6.474,6.229,6.195,6.715,5.913,6.092,6.254,5.928,6.176,6.021,5.872,5.731,5.87,6.004,5.961,5.856,5.879,5.986,5.613,5.693,6.431,5.637,6.458,6.326,6.372,5.822,5.757,6.335,5.942,6.454,5.857,6.151,6.174,5.019,5.403,5.468,4.903,6.13,5.628,4.926,5.186,5.597,6.122,5.404,5.012,5.709,6.129,6.152,5.272,6.943,6.066,6.51,6.25,7.489,7.802,8.375,5.854,6.101,7.929,5.877,6.319,6.402,5.875,5.88,5.572,6.416,5.859,6.546,6.02,6.315,6.86,6.98,7.765,6.144,7.155,6.563,5.604,6.153,7.831,6.782,6.556,7.185,6.951,6.739,7.178,6.8,6.604,7.875,7.287,7.107,7.274,6.975,7.135,6.162,7.61,7.853,8.034,5.891,6.326,5.783,6.064,5.344,5.96,5.404,5.807,6.375,5.412,6.182,5.888,6.642,5.951,6.373,6.951,6.164,6.879,6.618,8.266,8.725,8.04,7.163,7.686,6.552,5.981,7.412,8.337,8.247,6.726,6.086,6.631,7.358,6.481,6.606,6.897,6.095,6.358,6.393,5.593,5.605,6.108,6.226,6.433,6.718],\"type\":\"box\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"name\":\"AGE\",\"y\":[65.2,78.9,61.1,45.8,54.2,58.7,66.6,96.1,100.0,85.9,94.3,82.9,39.0,61.8,84.5,56.5,29.3,81.7,36.6,69.5,98.1,89.2,91.7,100.0,94.1,85.7,90.3,88.8,94.4,87.3,94.1,100.0,82.0,95.0,96.9,68.2,61.4,41.5,30.2,21.8,15.8,2.9,6.6,6.5,40.0,33.8,33.3,85.5,95.3,62.0,45.7,63.0,21.1,21.4,47.6,21.9,35.7,40.5,29.2,47.2,66.2,93.4,67.8,43.4,59.5,17.8,31.1,21.4,36.8,33.0,6.6,17.5,7.8,6.2,6.0,45.0,74.5,45.8,53.7,36.6,33.5,70.4,32.2,46.7,48.0,56.1,45.1,56.8,86.3,63.1,66.1,73.9,53.6,28.9,77.3,57.8,69.6,76.0,36.9,62.5,79.9,71.3,85.4,87.4,90.0,96.7,91.9,85.2,97.1,91.2,54.4,81.6,92.9,95.4,84.2,88.2,72.5,82.6,73.1,65.2,69.7,84.1,92.9,97.0,95.8,88.4,95.6,96.0,98.8,94.7,98.9,97.7,97.9,95.4,98.4,98.2,93.5,98.4,98.2,97.9,93.6,100.0,100.0,100.0,97.8,100.0,100.0,95.7,93.8,94.9,97.3,100.0,88.0,98.5,96.0,82.6,94.0,97.4,100.0,100.0,92.6,90.8,98.2,93.9,91.8,93.0,96.2,79.2,96.1,95.2,94.6,97.3,88.5,84.1,68.7,33.1,47.2,73.4,74.4,58.4,83.3,62.2,92.2,95.6,89.8,68.8,53.6,41.1,29.1,38.9,21.5,30.8,26.3,9.9,18.8,32.0,34.1,36.6,38.3,15.3,13.9,38.4,15.7,33.2,31.9,22.3,52.5,72.7,59.1,100.0,92.1,88.6,53.8,32.3,9.8,42.4,56.0,85.1,93.8,92.4,88.5,91.3,77.7,80.8,78.3,83.0,86.5,79.9,17.0,21.4,68.1,76.9,73.3,70.4,66.5,61.5,76.5,71.6,18.5,42.2,54.3,65.1,52.9,7.8,76.5,70.2,34.9,79.2,49.1,17.5],\"type\":\"box\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"name\":\"DIS\",\"y\":[4.09,4.9671,4.9671,6.0622,6.0622,6.0622,5.5605,5.9505,6.0821,6.5921,6.3467,6.2267,5.4509,4.7075,4.4619,4.4986,4.4986,4.2579,3.7965,3.7965,3.7979,4.0123,3.9769,4.0952,4.3996,4.4546,4.682,4.4534,4.4547,4.239,4.233,4.175,3.99,3.7872,3.7598,3.3603,3.3779,3.9342,3.8473,5.4011,5.4011,5.7209,5.7209,5.7209,5.7209,5.1004,5.1004,5.6894,5.87,6.0877,6.8147,6.8147,6.8147,6.8147,7.3197,8.6966,9.1876,8.3248,7.8148,6.932,7.2254,6.8185,7.2255,7.9809,9.2229,6.6115,6.6115,6.498,6.498,6.498,5.2873,5.2873,5.2873,5.2873,4.2515,4.5026,4.0522,4.0905,5.0141,4.5026,5.4007,5.4007,5.4007,5.4007,4.7794,4.4377,4.4272,3.7476,3.4217,3.4145,3.0923,3.0921,3.6659,3.6659,3.615,3.4952,3.4952,3.4952,3.4952,3.4952,2.7778,2.8561,2.7147,2.7147,2.421,2.1069,2.211,2.1224,2.4329,2.5451,2.7778,2.6775,2.3534,2.548,2.2565,2.4631,2.7301,2.7474,2.4775,2.7592,2.2577,2.1974,2.0869,1.9444,2.0063,1.9929,1.7572,1.7883,1.8125,1.9799,2.1185,2.271,2.3274,2.4699,2.346,2.1107,1.9669,1.8498,1.6686,1.6687,1.6119,1.4394,1.3216,1.4118,1.3459,1.4191,1.5166,1.4608,1.5296,1.5257,1.618,1.5916,1.6102,1.6232,1.7494,1.7455,1.7364,1.8773,1.7573,1.7659,1.7984,1.9709,2.0407,2.162,2.422,2.2834,2.0459,2.4259,2.1,2.2625,2.4259,2.3887,2.5961,2.6463,2.7019,3.1323,3.5549,3.3175,2.9153,2.829,2.741,2.5979,2.7006,2.847,2.9879,3.2797,3.1992,3.7886,4.5667,4.5667,6.4798,6.4798,6.4798,6.2196,6.2196,5.6484,7.309,7.309,7.309,7.6534,7.6534,6.27,6.27,5.118,5.118,3.9454,4.3549,4.3549,4.2392,3.875,3.8771,3.665,3.6526,3.9454,3.5875,3.9454,3.1121,3.4211,2.8893,3.3633,2.8617,3.048,3.2721,3.2721,2.8944,2.8944,3.2157,3.2157,3.3751,3.3751,3.6715,3.6715,3.8384,3.6519,3.6519,3.6519,4.148,4.148,6.1899,6.1899,6.3361,6.3361,7.0355,7.0355,7.9549,7.9549,8.0555,8.0555,7.8265,7.8265],\"type\":\"box\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"name\":\"RAD\",\"y\":[1.0,2.0,2.0,3.0,3.0,3.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,4.0,4.0,4.0,4.0,3.0,5.0,2.0,5.0,8.0,8.0,8.0,8.0,8.0,8.0,3.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,3.0,3.0,3.0,3.0,2.0,2.0,2.0,2.0,4.0,4.0,4.0,2.0,2.0,2.0,2.0,2.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,5.0,5.0,5.0,5.0,5.0,5.0,1.0,1.0,4.0,2.0,2.0,2.0,3.0,3.0,2.0,2.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,6.0,6.0,6.0,6.0,6.0,6.0,7.0,7.0,7.0,7.0,7.0,7.0],\"type\":\"box\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"name\":\"TAX\",\"y\":[296.0,242.0,242.0,222.0,222.0,222.0,311.0,311.0,311.0,311.0,311.0,311.0,311.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,279.0,279.0,279.0,279.0,252.0,252.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,243.0,243.0,243.0,243.0,469.0,226.0,313.0,256.0,284.0,284.0,284.0,284.0,284.0,284.0,216.0,337.0,337.0,345.0,345.0,345.0,305.0,305.0,305.0,305.0,398.0,398.0,398.0,398.0,398.0,398.0,281.0,281.0,281.0,281.0,247.0,247.0,247.0,247.0,270.0,270.0,270.0,270.0,270.0,270.0,270.0,276.0,276.0,276.0,276.0,276.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,188.0,188.0,188.0,188.0,188.0,188.0,188.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,296.0,296.0,296.0,296.0,296.0,296.0,296.0,193.0,193.0,193.0,193.0,193.0,193.0,193.0,193.0,398.0,398.0,398.0,398.0,398.0,398.0,265.0,265.0,255.0,329.0,329.0,329.0,402.0,402.0,348.0,348.0,224.0,224.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,276.0,276.0,276.0,276.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,300.0,300.0,300.0,300.0,300.0,300.0,330.0,330.0,330.0,330.0,330.0,330.0],\"type\":\"box\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"},{\"name\":\"PTRATIO\",\"y\":[15.3,17.8,17.8,18.7,18.7,18.7,15.2,15.2,15.2,15.2,15.2,15.2,15.2,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,19.2,19.2,19.2,19.2,18.3,18.3,17.9,17.9,17.9,17.9,17.9,17.9,17.9,17.9,17.9,16.8,16.8,16.8,16.8,21.1,17.9,17.3,15.1,19.7,19.7,19.7,19.7,19.7,19.7,18.6,16.1,16.1,18.9,18.9,18.9,19.2,19.2,19.2,19.2,18.7,18.7,18.7,18.7,18.7,18.7,19.0,19.0,19.0,19.0,18.5,18.5,18.5,18.5,17.8,17.8,17.8,17.8,18.2,18.2,18.2,18.0,18.0,18.0,18.0,18.0,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,19.1,19.1,19.1,19.1,19.1,19.1,19.1,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,16.6,16.6,16.6,16.6,16.6,16.6,16.6,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,15.2,15.2,15.2,15.2,15.2,15.2,15.6,15.6,14.4,12.6,12.6,12.6,17.0,17.0,14.7,14.7,14.7,14.7,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,16.4,16.4,16.4,16.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,16.6,16.6,16.6,16.6,16.6,16.6,19.1,19.1,19.1,19.1,19.1,19.1],\"type\":\"box\",\"xaxis\":\"x11\",\"yaxis\":\"y11\"},{\"name\":\"B\",\"y\":[396.9,396.9,392.83,394.63,396.9,394.12,395.6,396.9,386.63,386.71,392.52,396.9,390.5,396.9,380.02,395.62,386.85,386.75,288.99,390.95,376.57,392.53,396.9,394.54,394.33,303.42,376.88,306.38,387.94,380.23,360.17,376.73,232.6,358.77,248.31,396.9,377.56,396.9,393.43,395.63,395.62,385.41,383.37,394.46,389.39,396.9,396.9,392.74,396.9,396.9,395.56,393.97,396.9,396.9,396.9,395.93,396.9,392.9,390.68,396.9,395.11,378.08,396.9,395.58,393.24,396.9,396.9,396.21,396.9,396.9,383.73,376.94,390.91,377.17,394.92,383.23,373.66,386.96,386.4,396.06,396.9,395.63,396.9,390.64,396.9,392.3,395.99,395.15,396.9,396.06,392.18,393.55,395.01,396.33,396.9,357.98,391.83,396.9,393.53,396.9,394.76,395.58,70.8,394.47,392.69,394.05,395.67,387.69,395.24,391.23,393.49,395.59,394.95,396.9,388.74,344.91,393.3,394.51,338.63,391.5,389.15,377.67,378.09,370.31,379.38,385.02,359.29,392.11,396.9,396.9,395.04,396.9,385.76,388.69,262.76,394.67,378.25,394.08,392.04,396.9,388.08,396.9,396.9,396.9,396.9,172.91,169.27,391.71,356.99,351.85,372.8,341.6,343.28,261.95,321.02,88.01,88.63,363.43,353.89,364.31,338.92,374.43,389.61,388.45,395.11,240.16,369.3,227.61,297.09,330.04,292.29,348.13,396.9,395.5,393.23,390.96,393.23,395.6,391.27,396.9,395.56,396.9,394.12,396.9,391.0,387.11,392.63,393.87,382.84,396.9,377.68,389.71,390.49,393.37,376.7,394.23,396.9,354.31,392.2,396.9,384.3,393.77,395.38,392.78,390.55,396.9,394.87,389.43,381.32,396.9,393.25,395.24,390.94,385.81,348.93,393.63,392.8,392.78,396.9,393.74,391.7,395.24,390.39,396.9,385.05,382.0,387.38,372.08,377.51,380.34,378.35,376.14,385.91,378.95,360.2,376.75,388.45,390.07,379.41,383.78,391.25,394.62,372.75,374.71,372.49,389.13,390.18,376.14,374.71,393.74],\"type\":\"box\",\"xaxis\":\"x12\",\"yaxis\":\"y12\"},{\"name\":\"LSTAT\",\"y\":[4.98,9.14,4.03,2.94,5.33,5.21,12.43,19.15,29.93,17.1,20.45,13.27,15.71,8.26,10.26,8.47,6.58,14.67,11.69,11.28,21.02,13.83,18.72,19.88,16.3,16.51,14.81,17.28,12.8,11.98,22.6,13.04,27.71,18.35,20.34,9.68,11.41,8.77,10.13,4.32,1.98,4.84,5.81,7.44,9.55,10.21,14.15,18.8,30.81,16.2,13.45,9.43,5.28,8.43,14.8,4.81,5.77,3.95,6.86,9.22,13.15,14.44,6.73,9.5,8.05,4.67,10.24,8.1,13.09,8.79,6.72,9.88,5.52,7.54,6.78,8.94,11.97,10.27,12.34,9.1,5.29,7.22,6.72,7.51,9.62,6.53,12.86,8.44,5.5,5.7,8.81,8.2,8.16,6.21,10.59,6.65,11.34,4.21,3.57,6.19,9.42,7.67,10.63,13.44,12.33,16.47,18.66,14.09,12.27,15.55,13.0,10.16,16.21,17.09,10.45,15.76,12.04,10.3,15.37,13.61,14.37,14.27,17.93,25.41,17.58,14.81,27.26,17.19,15.39,18.34,12.6,12.26,11.12,15.03,17.31,16.96,16.9,14.59,21.32,18.46,24.16,34.41,26.82,26.42,29.29,27.8,16.65,29.53,28.32,21.45,14.1,13.28,12.12,15.79,15.12,15.02,16.14,4.59,6.43,7.39,5.5,1.73,1.92,3.32,11.64,9.81,3.7,12.14,11.1,11.32,14.43,12.03,14.69,9.04,9.64,5.33,10.11,6.29,6.92,5.04,7.56,9.45,4.82,5.68,13.98,13.15,4.45,6.68,4.56,5.39,5.1,4.69,2.87,5.03,4.38,2.97,4.08,8.61,6.62,4.56,4.45,7.43,3.11,3.81,2.88,10.87,10.97,18.06,14.66,23.09,17.27,23.98,16.03,9.38,29.55,9.47,13.51,9.69,17.92,10.5,9.71,21.46,9.93,7.6,4.14,4.63,3.13,6.36,3.92,3.76,11.65,5.25,2.47,3.95,8.05,10.88,9.54,4.73,6.36,7.37,11.38,12.4,11.22,5.19,12.5,18.46,9.16,10.15,9.52,6.56],\"type\":\"box\",\"xaxis\":\"x13\",\"yaxis\":\"y13\"},{\"name\":\"MEDV\",\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"box\",\"xaxis\":\"x14\",\"yaxis\":\"y14\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.848,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.848,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.848,1.0]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,0.2888888888888889]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.6359999999999999,0.7879999999999999]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.6359999999999999,0.7879999999999999]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.7111111111111111,1.0]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.6359999999999999,0.7879999999999999]},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.0,0.2888888888888889]},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.424,0.576]},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.424,0.576]},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.7111111111111111,1.0]},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.424,0.576]},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.0,0.2888888888888889]},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.212,0.364]},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.212,0.364]},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.7111111111111111,1.0]},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.212,0.364]},\"xaxis13\":{\"anchor\":\"y13\",\"domain\":[0.0,0.2888888888888889]},\"yaxis13\":{\"anchor\":\"x13\",\"domain\":[0.0,0.152]},\"xaxis14\":{\"anchor\":\"y14\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis14\":{\"anchor\":\"x14\",\"domain\":[0.0,0.152]},\"xaxis15\":{\"anchor\":\"y15\",\"domain\":[0.7111111111111111,1.0]},\"yaxis15\":{\"anchor\":\"x15\",\"domain\":[0.0,0.152]},\"height\":1000,\"width\":550,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('337044ea-b7f6-48e3-bfd4-6418fd042d52');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "\n",
        "total_items = len(df.columns)\n",
        "items_per_row = 3\n",
        "total_rows = math.ceil(total_items / items_per_row)\n",
        "\n",
        "fig = make_subplots(rows=total_rows, cols=items_per_row)\n",
        "\n",
        "cur_row = 1\n",
        "cur_col = 1\n",
        "\n",
        "for index, column in enumerate(df.columns):\n",
        "    fig.add_trace(go.Box(y=df[column], name=column), row=cur_row, col=cur_col)\n",
        "    \n",
        "    if cur_col % items_per_row == 0:\n",
        "        cur_col = 1\n",
        "        cur_row = cur_row + 1\n",
        "    else:\n",
        "        cur_col = cur_col + 1\n",
        "    \n",
        "\n",
        "fig.update_layout(height=1000, width=550,  showlegend=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uraEkzX1y8In"
      },
      "source": [
        "These results do corroborate our initial assumptions about having outliers in some columns. Let's also plot some scatter plots for each feature and the target variable, as well as their intercept lines:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gNCdY1JPy8In",
        "outputId": "c29761ea-2e60-48e8-85ee-e7091ca86c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b518d61d-af4e-41e0-9a4c-6ac801bb00ea\" class=\"plotly-graph-div\" style=\"height:1000px; width:550px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b518d61d-af4e-41e0-9a4c-6ac801bb00ea\")) {                    Plotly.newPlot(                        \"b518d61d-af4e-41e0-9a4c-6ac801bb00ea\",                        [{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[0.00632,0.02731,0.02729,0.03237,0.06905,0.02985,0.08829,0.14455,0.21124,0.17004,0.22489,0.11747,0.09378,0.62976,0.63796,0.62739,1.05393,0.7842,0.80271,0.7258,1.25179,0.85204,1.23247,0.98843,0.75026,0.84054,0.67191,0.95577,0.77299,1.00245,1.13081,1.35472,1.38799,1.15172,1.61282,0.06417,0.09744,0.08014,0.17505,0.02763,0.03359,0.12744,0.1415,0.15936,0.12269,0.17142,0.18836,0.22927,0.25387,0.21977,0.08873,0.04337,0.0536,0.04981,0.0136,0.01311,0.02055,0.01432,0.15445,0.10328,0.14932,0.17171,0.11027,0.1265,0.01951,0.03584,0.04379,0.05789,0.13554,0.12816,0.08826,0.15876,0.09164,0.19539,0.07896,0.09512,0.10153,0.08707,0.05646,0.08387,0.04113,0.04462,0.03659,0.03551,0.05059,0.05735,0.05188,0.07151,0.0566,0.05302,0.04684,0.03932,0.04203,0.02875,0.04294,0.12204,0.11504,0.12083,0.08187,0.0686,0.14866,0.11432,0.22876,0.21161,0.1396,0.13262,0.1712,0.13117,0.12802,0.26363,0.10793,0.10084,0.12329,0.22212,0.14231,0.17134,0.13158,0.15098,0.13058,0.14476,0.06899,0.07165,0.09299,0.15038,0.09849,0.16902,0.38735,0.25915,0.32543,0.88125,0.34006,1.19294,0.59005,0.32982,0.97617,0.55778,0.32264,0.35233,0.2498,0.54452,0.2909,1.62864,3.32105,4.0974,2.77974,2.37934,2.15505,2.36862,2.33099,2.73397,1.6566,1.49632,1.12658,2.14918,1.41385,3.53501,2.44668,1.22358,1.34284,1.42502,1.27346,1.46336,1.83377,1.51902,2.24236,2.924,2.01019,1.80028,2.3004,2.44953,1.20742,2.3139,0.13914,0.09178,0.08447,0.06664,0.07022,0.05425,0.06642,0.0578,0.06588,0.06888,0.09103,0.10008,0.08308,0.06047,0.05602,0.07875,0.12579,0.0837,0.09068,0.06911,0.08664,0.02187,0.01439,0.01381,0.04011,0.04666,0.03768,0.0315,0.01778,0.03445,0.02177,0.0351,0.02009,0.13642,0.22969,0.25199,0.13587,0.43571,0.17446,0.37578,0.21719,0.14052,0.28955,0.19802,0.0456,0.07013,0.11069,0.11425,0.35809,0.40771,0.62356,0.6147,0.31533,0.52693,0.38214,0.41238,0.29819,0.44178,0.537,0.46296,0.57529,0.33147,0.44791,0.33045,0.52058,0.51183,0.08244,0.09252,0.11329,0.10612,0.1029,0.12757,0.20608,0.19133,0.33983,0.19657,0.16439,0.19073],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[0.00632,0.01311,0.0136,0.01381,0.01432,0.01439,0.01778,0.01951,0.02009,0.02055,0.02177,0.02187,0.02729,0.02731,0.02763,0.02875,0.02985,0.0315,0.03237,0.03359,0.03445,0.0351,0.03551,0.03584,0.03659,0.03768,0.03932,0.04011,0.04113,0.04203,0.04294,0.04337,0.04379,0.04462,0.0456,0.04666,0.04684,0.04981,0.05059,0.05188,0.05302,0.0536,0.05425,0.05602,0.05646,0.0566,0.05735,0.0578,0.05789,0.06047,0.06417,0.06588,0.06642,0.06664,0.0686,0.06888,0.06899,0.06905,0.06911,0.07013,0.07022,0.07151,0.07165,0.07875,0.07896,0.08014,0.08187,0.08244,0.08308,0.0837,0.08387,0.08447,0.08664,0.08707,0.08826,0.08829,0.08873,0.09068,0.09103,0.09164,0.09178,0.09252,0.09299,0.09378,0.09512,0.09744,0.09849,0.10008,0.10084,0.10153,0.1029,0.10328,0.10612,0.10793,0.11027,0.11069,0.11329,0.11425,0.11432,0.11504,0.11747,0.12083,0.12204,0.12269,0.12329,0.12579,0.1265,0.12744,0.12757,0.12802,0.12816,0.13058,0.13117,0.13158,0.13262,0.13554,0.13587,0.13642,0.13914,0.1396,0.14052,0.1415,0.14231,0.14455,0.14476,0.14866,0.14932,0.15038,0.15098,0.15445,0.15876,0.15936,0.16439,0.16902,0.17004,0.1712,0.17134,0.17142,0.17171,0.17446,0.17505,0.18836,0.19073,0.19133,0.19539,0.19657,0.19802,0.20608,0.21124,0.21161,0.21719,0.21977,0.22212,0.22489,0.22876,0.22927,0.22969,0.2498,0.25199,0.25387,0.25915,0.26363,0.28955,0.2909,0.29819,0.31533,0.32264,0.32543,0.32982,0.33045,0.33147,0.33983,0.34006,0.35233,0.35809,0.37578,0.38214,0.38735,0.40771,0.41238,0.43571,0.44178,0.44791,0.46296,0.51183,0.52058,0.52693,0.537,0.54452,0.55778,0.57529,0.59005,0.6147,0.62356,0.62739,0.62976,0.63796,0.67191,0.7258,0.75026,0.77299,0.7842,0.80271,0.84054,0.85204,0.88125,0.95577,0.97617,0.98843,1.00245,1.05393,1.12658,1.13081,1.15172,1.19294,1.20742,1.22358,1.23247,1.25179,1.27346,1.34284,1.35472,1.38799,1.41385,1.42502,1.46336,1.49632,1.51902,1.61282,1.62864,1.6566,1.80028,1.83377,2.01019,2.14918,2.15505,2.24236,2.3004,2.3139,2.33099,2.36862,2.37934,2.44668,2.44953,2.73397,2.77974,2.924,3.32105,3.53501,4.0974],\"y\":[25.512328712513167,25.49465985887517,25.49338478696315,25.492838327572287,25.491511211908755,25.491329058778465,25.482507642897346,25.47800585839164,25.476496589597822,25.475299583313067,25.472124914470893,25.47186469571334,25.457760839053847,25.457708795302338,25.45687609527816,25.453961645193544,25.451099238860436,25.446805629360775,25.444541726170048,25.441367057327874,25.439129176012898,25.43743775408879,25.436370857182816,25.43551213528288,25.433560494601217,25.430724110143867,25.426456522519963,25.424400794335277,25.421746563008213,25.419404594190215,25.417036603496467,25.41591766283898,25.414824744057245,25.412664928369537,25.4101147845455,25.407356465715413,25.406888071951812,25.399159574852426,25.397129868543495,25.393773046571035,25.390806552734904,25.389297283941083,25.387605862016976,25.382999990008248,25.381855027475005,25.38149072121443,25.379539080532766,25.37836809612377,25.378133899241966,25.371420255297043,25.361792161267502,25.35734242051331,25.355937239222513,25.35536475795589,25.35026447030781,25.349535857786655,25.349249617153344,25.349093485898813,25.348937354644278,25.346283123317214,25.346048926435415,25.342692104462955,25.342327798202376,25.32385226641596,25.323305807025093,25.320235225685945,25.31573344118024,25.314250194262176,25.312584794213823,25.31097143791698,25.310529066029137,25.308967753483806,25.303321006444857,25.30220206578737,25.299105462572463,25.299027396945196,25.297882434411953,25.292808168639628,25.291897402988187,25.2903100685671,25.289945762306523,25.288020143500614,25.286797115340104,25.284741387155417,25.28125445580418,25.2752173806289,25.27248508367457,25.268347605429444,25.266369942872025,25.264574433444892,25.261009436466388,25.260020605187677,25.25263039247311,25.24792043296136,25.24183131403457,25.24073839525284,25.233972707556404,25.231474607483875,25.231292454353586,25.22941887929919,25.2230955634906,25.214352213236747,25.211203566270328,25.20951214434622,25.20795083180089,25.20144536286201,25.199597809683368,25.19715175336235,25.196813468977528,25.19564248456853,25.19527817830795,25.188980884375116,25.187445593705544,25.186378696799565,25.183672421720992,25.176074034000383,25.17521531210045,25.173784108933894,25.166706158728395,25.16550915244364,25.163115139874133,25.160564996050095,25.158457224113896,25.15262832394466,25.152081864553796,25.141933333009142,25.14021588920928,25.137457570379194,25.135896257833863,25.1268666669467,25.11565123849607,25.11408992595074,25.101000922445717,25.08895279397091,25.086298562643847,25.083280025056208,25.082915718795633,25.08270754378959,25.081952909392676,25.07479689355991,25.073261602890334,25.038626486259744,25.032459301705686,25.030897989160355,25.020333107603616,25.017262526264464,25.013489354279912,24.99251572242097,24.97908843453112,24.97812562512817,24.963605418456588,24.956891774511664,24.95077663370912,24.94356857412484,24.933498108207456,24.932170992543924,24.931078073762194,24.87874808161785,24.87304929082739,24.868157178185353,24.85441762778644,24.84275982744797,24.77531112548967,24.771798172262674,24.752828224836904,24.70822672979195,24.689204738614666,24.681944635278878,24.670521031822204,24.668881653649606,24.666227422322546,24.64447313419093,24.643874631048554,24.611945789496538,24.59695718906136,24.55092449084985,24.534374577869343,24.52081718060072,24.467836641562485,24.45568442558466,24.39497538944704,24.37918011086344,24.36322870102531,24.324065778013257,24.196896871196046,24.17412772990997,24.157603838805215,24.13139980991941,24.111831359351264,24.077326352099448,24.03176204765154,23.993353759036395,23.929209835299048,23.90615445337966,23.8961880749653,23.89002089041124,23.868682952291717,23.78033868410174,23.64010679565526,23.576457287557265,23.517309563964975,23.48813904124304,23.43997254921958,23.341531793236463,23.311606636117617,23.235596737035753,23.041681718905643,22.98859709236439,22.956694272688125,22.920211602878894,22.78625098648949,22.597202059125664,22.58619480568108,22.531783063476297,22.424520891612058,22.386841215518068,22.344789864297155,22.3216564167505,22.271382152790842,22.214992748028635,22.034452974036864,22.00353898563931,21.916964205000706,21.84967163429694,21.820605199078027,21.720837327431376,21.635069224941194,21.575999566976172,21.331914372389427,21.2907477649442,21.217990600331774,20.844108289476512,20.756961027571286,20.297883095492463,19.936205044366538,19.92093020329805,19.693733206076633,19.542702239191616,19.507572706921668,19.46310132125549,19.36518100278748,19.33728555197757,19.162054240639918,19.154638006049595,18.414471772059684,18.295369646726684,17.9199780670776,16.886779490204816,16.33001543653978,14.866571165925283],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[18.0,0.0,0.0,0.0,0.0,0.0,12.5,12.5,12.5,12.5,12.5,12.5,12.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,75.0,75.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,21.0,21.0,21.0,21.0,75.0,90.0,85.0,100.0,25.0,25.0,25.0,25.0,25.0,25.0,17.5,80.0,80.0,12.5,12.5,12.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,25.0,25.0,25.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,28.0,28.0,28.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,45.0,45.0,45.0,45.0,45.0,45.0,60.0,60.0,80.0,80.0,80.0,80.0,95.0,95.0,82.5,82.5,95.0,95.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,30.0,30.0,30.0,30.0,30.0,30.0,22.0,22.0,22.0,22.0,22.0,22.0],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[0.0,12.5,17.5,18.0,21.0,22.0,25.0,28.0,30.0,45.0,60.0,75.0,80.0,82.5,85.0,90.0,95.0,100.0],\"y\":[23.014860739597488,24.428533948921274,24.994003232650787,25.05055016102374,25.389831731261445,25.50292558800735,25.842207158245056,26.181488728482766,26.407676441974573,28.104084293163112,29.800492144351654,31.496899995540197,32.06236927926971,32.345103921134466,32.62783856299922,33.19330784672874,33.758777130458256,34.32424641418777],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[2.31,7.07,7.07,2.18,2.18,2.18,7.87,7.87,7.87,7.87,7.87,7.87,7.87,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,8.14,5.96,5.96,5.96,5.96,2.95,2.95,6.91,6.91,6.91,6.91,6.91,6.91,6.91,6.91,6.91,5.64,5.64,5.64,5.64,4.0,1.22,0.74,1.32,5.13,5.13,5.13,5.13,5.13,5.13,1.38,3.37,3.37,6.07,6.07,6.07,10.81,10.81,10.81,10.81,12.83,12.83,12.83,12.83,12.83,12.83,4.86,4.86,4.86,4.86,4.49,4.49,4.49,4.49,3.41,3.41,3.41,3.41,15.04,15.04,15.04,2.89,2.89,2.89,2.89,2.89,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,8.56,10.01,10.01,10.01,10.01,10.01,10.01,10.01,10.01,10.01,25.65,25.65,25.65,25.65,25.65,25.65,25.65,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,21.89,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,19.58,4.05,4.05,4.05,4.05,4.05,4.05,4.05,2.46,2.46,2.46,2.46,2.46,2.46,2.46,2.46,3.44,3.44,3.44,3.44,3.44,3.44,2.93,2.93,0.46,1.52,1.52,1.52,1.47,1.47,2.03,2.03,2.68,2.68,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,10.59,13.89,13.89,13.89,13.89,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,6.2,4.93,4.93,4.93,4.93,4.93,4.93,5.86,5.86,5.86,5.86,5.86,5.86],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[0.46,0.74,1.22,1.32,1.38,1.47,1.52,2.03,2.18,2.31,2.46,2.68,2.89,2.93,2.95,3.37,3.41,3.44,4.0,4.05,4.49,4.86,4.93,5.13,5.64,5.86,5.96,6.07,6.2,6.91,7.07,7.87,8.14,8.56,10.01,10.59,10.81,12.83,13.89,15.04,19.58,21.89,25.65],\"y\":[28.421720024662182,28.29422174066312,28.07565325380758,28.030118152379345,28.002797091522403,27.961815500236987,27.93904794952287,27.70681893223886,27.638516280096503,27.579320648239797,27.51101799609744,27.41084077295532,27.315217059956023,27.29700301938473,27.287895999099078,27.096648573100484,27.07843453252919,27.06477400210072,26.80977743410259,26.78700988338847,26.586655437104227,26.41817556181975,26.386300990819986,26.29523078796351,26.063001770679502,25.96282454753738,25.917289446109145,25.86720083453808,25.808005202681375,25.48470598254089,25.41184982025571,25.047569008829814,24.924624234973574,24.73337680897498,24.073117838265542,23.809014249981768,23.708837026839646,22.789027977989257,22.306355902849944,21.782702236425216,19.715408631583255,18.66354778859098,16.951427974889263],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[0.0,1.0],\"y\":[24.248260869565215,24.694999999999997],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[0.538,0.469,0.469,0.458,0.458,0.458,0.524,0.524,0.524,0.524,0.524,0.524,0.524,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.538,0.499,0.499,0.499,0.499,0.428,0.428,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.448,0.439,0.439,0.439,0.439,0.41,0.403,0.41,0.411,0.453,0.453,0.453,0.453,0.453,0.453,0.4161,0.398,0.398,0.409,0.409,0.409,0.413,0.413,0.413,0.413,0.437,0.437,0.437,0.437,0.437,0.437,0.426,0.426,0.426,0.426,0.449,0.449,0.449,0.449,0.489,0.489,0.489,0.489,0.464,0.464,0.464,0.445,0.445,0.445,0.445,0.445,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.547,0.581,0.581,0.581,0.581,0.581,0.581,0.581,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.624,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.871,0.605,0.605,0.871,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.605,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.488,0.488,0.488,0.488,0.488,0.488,0.488,0.488,0.437,0.437,0.437,0.437,0.437,0.437,0.401,0.401,0.422,0.404,0.404,0.404,0.403,0.403,0.415,0.415,0.4161,0.4161,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.489,0.55,0.55,0.55,0.55,0.507,0.507,0.507,0.507,0.504,0.504,0.504,0.504,0.504,0.504,0.504,0.504,0.507,0.507,0.507,0.507,0.507,0.507,0.428,0.428,0.428,0.428,0.428,0.428,0.431,0.431,0.431,0.431,0.431,0.431],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[0.398,0.401,0.403,0.404,0.409,0.41,0.411,0.413,0.415,0.4161,0.422,0.426,0.428,0.431,0.437,0.439,0.445,0.448,0.449,0.453,0.458,0.464,0.469,0.488,0.489,0.499,0.504,0.507,0.51,0.52,0.524,0.538,0.547,0.55,0.581,0.605,0.624,0.871],\"y\":[27.411619394100715,27.335812529752843,27.285274620187593,27.260005665404968,27.13366089149185,27.108391936709225,27.0831229819266,27.032585072361353,26.982047162796107,26.95425131253522,26.80516447931774,26.70408866018724,26.653550750621992,26.57774388627412,26.426130157578374,26.375592248013128,26.22397851931738,26.14817165496951,26.122902700186884,26.021826881056388,25.895482107143266,25.743868378447523,25.617523604534405,25.137413463664544,25.11214450888192,24.85945496105568,24.733110187142557,24.657303322794682,24.581496458446814,24.32880691062057,24.227731091490075,23.873965724533335,23.646545131489717,23.57073826714185,22.7874006688805,22.18094575409752,21.70083561322766,15.459403781919502],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[6.575,6.421,7.185,6.998,7.147,6.43,6.012,6.172,5.631,6.004,6.377,6.009,5.889,5.949,6.096,5.834,5.935,5.99,5.456,5.727,5.57,5.965,6.142,5.813,5.924,5.599,5.813,6.047,6.495,6.674,5.713,6.072,5.95,5.701,6.096,5.933,5.841,5.85,5.966,6.595,7.024,6.77,6.169,6.211,6.069,5.682,5.786,6.03,5.399,5.602,5.963,6.115,6.511,5.998,5.888,7.249,6.383,6.816,6.145,5.927,5.741,5.966,6.456,6.762,7.104,6.29,5.787,5.878,5.594,5.885,6.417,5.961,6.065,6.245,6.273,6.286,6.279,6.14,6.232,5.874,6.727,6.619,6.302,6.167,6.389,6.63,6.015,6.121,7.007,7.079,6.417,6.405,6.442,6.211,6.249,6.625,6.163,8.069,7.82,7.416,6.727,6.781,6.405,6.137,6.167,5.851,5.836,6.127,6.474,6.229,6.195,6.715,5.913,6.092,6.254,5.928,6.176,6.021,5.872,5.731,5.87,6.004,5.961,5.856,5.879,5.986,5.613,5.693,6.431,5.637,6.458,6.326,6.372,5.822,5.757,6.335,5.942,6.454,5.857,6.151,6.174,5.019,5.403,5.468,4.903,6.13,5.628,4.926,5.186,5.597,6.122,5.404,5.012,5.709,6.129,6.152,5.272,6.943,6.066,6.51,6.25,7.489,7.802,8.375,5.854,6.101,7.929,5.877,6.319,6.402,5.875,5.88,5.572,6.416,5.859,6.546,6.02,6.315,6.86,6.98,7.765,6.144,7.155,6.563,5.604,6.153,7.831,6.782,6.556,7.185,6.951,6.739,7.178,6.8,6.604,7.875,7.287,7.107,7.274,6.975,7.135,6.162,7.61,7.853,8.034,5.891,6.326,5.783,6.064,5.344,5.96,5.404,5.807,6.375,5.412,6.182,5.888,6.642,5.951,6.373,6.951,6.164,6.879,6.618,8.266,8.725,8.04,7.163,7.686,6.552,5.981,7.412,8.337,8.247,6.726,6.086,6.631,7.358,6.481,6.606,6.897,6.095,6.358,6.393,5.593,5.605,6.108,6.226,6.433,6.718],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[4.903,4.926,5.012,5.019,5.186,5.272,5.344,5.399,5.403,5.404,5.412,5.456,5.468,5.57,5.572,5.593,5.594,5.597,5.599,5.602,5.604,5.605,5.613,5.628,5.631,5.637,5.682,5.693,5.701,5.709,5.713,5.727,5.731,5.741,5.757,5.783,5.786,5.787,5.807,5.813,5.822,5.834,5.836,5.841,5.85,5.851,5.854,5.856,5.857,5.859,5.87,5.872,5.874,5.875,5.877,5.878,5.879,5.88,5.885,5.888,5.889,5.891,5.913,5.924,5.927,5.928,5.933,5.935,5.942,5.949,5.95,5.951,5.96,5.961,5.963,5.965,5.966,5.981,5.986,5.99,5.998,6.004,6.009,6.012,6.015,6.02,6.021,6.03,6.047,6.064,6.065,6.066,6.069,6.072,6.086,6.092,6.095,6.096,6.101,6.108,6.115,6.121,6.122,6.127,6.129,6.13,6.137,6.14,6.142,6.144,6.145,6.151,6.152,6.153,6.162,6.163,6.164,6.167,6.169,6.172,6.174,6.176,6.182,6.195,6.211,6.226,6.229,6.232,6.245,6.249,6.25,6.254,6.273,6.279,6.286,6.29,6.302,6.315,6.319,6.326,6.335,6.358,6.372,6.373,6.375,6.377,6.383,6.389,6.393,6.402,6.405,6.416,6.417,6.421,6.43,6.431,6.433,6.442,6.454,6.456,6.458,6.474,6.481,6.495,6.51,6.511,6.546,6.552,6.556,6.563,6.575,6.595,6.604,6.606,6.618,6.619,6.625,6.63,6.631,6.642,6.674,6.715,6.718,6.726,6.727,6.739,6.762,6.77,6.781,6.782,6.8,6.816,6.86,6.879,6.897,6.943,6.951,6.975,6.98,6.998,7.007,7.024,7.079,7.104,7.107,7.135,7.147,7.155,7.163,7.178,7.185,7.249,7.274,7.287,7.358,7.412,7.416,7.489,7.61,7.686,7.765,7.802,7.82,7.831,7.853,7.875,7.929,8.034,8.04,8.069,8.247,8.266,8.337,8.375,8.725],\"y\":[8.561464577273952,8.815225404875996,9.764070238518393,9.841301794745107,11.683826064725125,12.632670898367536,13.427052619556527,14.03387198990923,14.078004307753055,14.08903738721402,14.177302022901685,14.662757519183849,14.795154472715346,15.920528577733087,15.942594736654996,16.174289405335116,16.18532248479608,16.218421723178956,16.240487882100872,16.273587120483747,16.295653279405663,16.30668635886662,16.394950994554286,16.560447186468657,16.59354642485153,16.659744901617273,17.156233477360402,17.277597351430934,17.365861987118606,17.45412662280627,17.498258940650103,17.652722053103524,17.69685437094735,17.80718516555693,17.98371443693226,18.270574502917185,18.303673741300052,18.31470682076101,18.53536840998018,18.60156688674593,18.70086460189455,18.83326155542605,18.855327714347965,18.910493111652755,19.009790826801378,19.020823906262336,19.05392314464521,19.075989303567127,19.087022383028085,19.10908854195,19.23045241602054,19.252518574942457,19.274584733864373,19.28561781332533,19.307683972247247,19.318717051708205,19.329750131169163,19.34078321063012,19.395948607934912,19.429047846317786,19.44008092577876,19.46214708470066,19.704874832841753,19.826238706912292,19.859337945295152,19.870371024756125,19.925536422060915,19.947602580982817,20.024834137209538,20.102065693436245,20.113098772897203,20.12413185235816,20.223429567506784,20.234462646967742,20.25652880588966,20.278594964811575,20.289628044272533,20.455124236186904,20.510289633491695,20.554421951335527,20.642686587023192,20.70888506378894,20.764050461093746,20.797149699476606,20.83024893785948,20.88541433516427,20.89644741462523,20.995745129773866,21.18330748061014,21.37086983144644,21.3819029109074,21.392935990368358,21.426035228751232,21.459134467134106,21.61359757958752,21.67979605635327,21.712895294736143,21.7239283741971,21.77909377150189,21.856325327728598,21.933556883955305,21.999755360721053,22.01078844018201,22.065953837486802,22.08801999640872,22.099053075869676,22.176284632096383,22.209383870479257,22.231450029401188,22.25351618832309,22.264549267784048,22.330747744549797,22.341780824010755,22.352813903471713,22.452111618620336,22.463144698081308,22.474177777542252,22.507277015925126,22.529343174847043,22.562442413229917,22.584508572151847,22.606574731073763,22.672773207839512,22.816203240831967,22.992732512207297,23.15822870412167,23.191327942504543,23.224427180887417,23.367857213879873,23.411989531723705,23.423022611184663,23.467154929028496,23.6767834387867,23.74298191555245,23.820213471779155,23.864345789622988,23.996742743154485,24.140172776146954,24.184305093990787,24.26153665021748,24.360834365366117,24.614595192968153,24.769058305421567,24.780091384882525,24.80215754380444,24.824223702726357,24.890422179492106,24.956620656257854,25.000752974101687,25.10005068925031,25.133149927633184,25.254513801703737,25.26554688116468,25.309679199008528,25.408976914157137,25.420009993618095,25.44207615254001,25.541373867688648,25.67377082122013,25.69583698014206,25.717903139063978,25.894432410439308,25.971663966666014,26.126127079119428,26.2916232710338,26.302656350494757,26.68881413162829,26.75501260839404,26.799144926237872,26.87637648246458,27.00877343599609,27.22943502521524,27.328732740363876,27.350798899285792,27.48319585281729,27.494228932278247,27.560427409043996,27.615592806348786,27.626625885809744,27.747989759880284,28.101048302630957,28.553404560530225,28.586503798913114,28.67476843460078,28.685801514061737,28.818198467593234,29.07195929519527,29.160223930882935,29.281587804953475,29.292620884414433,29.49121631471168,29.66774558608701,30.15320108236918,30.36282959212737,30.56142502242463,31.068946677628702,31.157211313316367,31.42200522037936,31.477170617684166,31.675766047981412,31.77506376313002,31.962626113966323,32.56944548431902,32.84527247084297,32.87837170922586,33.18729793413267,33.319694887664184,33.40795952335185,33.496224159039514,33.661720350953885,33.73895190718059,34.44506899268191,34.72089597920588,34.86432601219833,35.64767465392636,36.24346094481811,36.28759326266194,37.093008063311885,38.42801067808783,39.26652471712066,40.13813799453635,40.5463619345918,40.74495736488906,40.8663212389596,41.10904898710068,41.35177673524176,41.94756302613351,43.106036369534124,43.17223484629986,43.49219415066766,45.456082294718215,45.66571080447642,46.449059446204444,46.868316465720866,50.72989427705623],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[65.2,78.9,61.1,45.8,54.2,58.7,66.6,96.1,100.0,85.9,94.3,82.9,39.0,61.8,84.5,56.5,29.3,81.7,36.6,69.5,98.1,89.2,91.7,100.0,94.1,85.7,90.3,88.8,94.4,87.3,94.1,100.0,82.0,95.0,96.9,68.2,61.4,41.5,30.2,21.8,15.8,2.9,6.6,6.5,40.0,33.8,33.3,85.5,95.3,62.0,45.7,63.0,21.1,21.4,47.6,21.9,35.7,40.5,29.2,47.2,66.2,93.4,67.8,43.4,59.5,17.8,31.1,21.4,36.8,33.0,6.6,17.5,7.8,6.2,6.0,45.0,74.5,45.8,53.7,36.6,33.5,70.4,32.2,46.7,48.0,56.1,45.1,56.8,86.3,63.1,66.1,73.9,53.6,28.9,77.3,57.8,69.6,76.0,36.9,62.5,79.9,71.3,85.4,87.4,90.0,96.7,91.9,85.2,97.1,91.2,54.4,81.6,92.9,95.4,84.2,88.2,72.5,82.6,73.1,65.2,69.7,84.1,92.9,97.0,95.8,88.4,95.6,96.0,98.8,94.7,98.9,97.7,97.9,95.4,98.4,98.2,93.5,98.4,98.2,97.9,93.6,100.0,100.0,100.0,97.8,100.0,100.0,95.7,93.8,94.9,97.3,100.0,88.0,98.5,96.0,82.6,94.0,97.4,100.0,100.0,92.6,90.8,98.2,93.9,91.8,93.0,96.2,79.2,96.1,95.2,94.6,97.3,88.5,84.1,68.7,33.1,47.2,73.4,74.4,58.4,83.3,62.2,92.2,95.6,89.8,68.8,53.6,41.1,29.1,38.9,21.5,30.8,26.3,9.9,18.8,32.0,34.1,36.6,38.3,15.3,13.9,38.4,15.7,33.2,31.9,22.3,52.5,72.7,59.1,100.0,92.1,88.6,53.8,32.3,9.8,42.4,56.0,85.1,93.8,92.4,88.5,91.3,77.7,80.8,78.3,83.0,86.5,79.9,17.0,21.4,68.1,76.9,73.3,70.4,66.5,61.5,76.5,71.6,18.5,42.2,54.3,65.1,52.9,7.8,76.5,70.2,34.9,79.2,49.1,17.5],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[2.9,6.0,6.2,6.5,6.6,7.8,9.8,9.9,13.9,15.3,15.7,15.8,17.0,17.5,17.8,18.5,18.8,21.1,21.4,21.5,21.8,21.9,22.3,26.3,28.9,29.1,29.2,29.3,30.2,30.8,31.1,31.9,32.0,32.2,32.3,33.0,33.1,33.2,33.3,33.5,33.8,34.1,34.9,35.7,36.6,36.8,36.9,38.3,38.4,38.9,39.0,40.0,40.5,41.1,41.5,42.2,42.4,43.4,45.0,45.1,45.7,45.8,46.7,47.2,47.6,48.0,49.1,52.5,52.9,53.6,53.7,53.8,54.2,54.3,54.4,56.0,56.1,56.5,56.8,57.8,58.4,58.7,59.1,59.5,61.1,61.4,61.5,61.8,62.0,62.2,62.5,63.0,63.1,65.1,65.2,66.1,66.2,66.5,66.6,67.8,68.1,68.2,68.7,68.8,69.5,69.6,69.7,70.2,70.4,71.3,71.6,72.5,72.7,73.1,73.3,73.4,73.9,74.4,74.5,76.0,76.5,76.9,77.3,77.7,78.3,78.9,79.2,79.9,80.8,81.6,81.7,82.0,82.6,82.9,83.0,83.3,84.1,84.2,84.5,85.1,85.2,85.4,85.5,85.7,85.9,86.3,86.5,87.3,87.4,88.0,88.2,88.4,88.5,88.6,88.8,89.2,89.8,90.0,90.3,90.8,91.2,91.3,91.7,91.8,91.9,92.1,92.2,92.4,92.6,92.9,93.0,93.4,93.5,93.6,93.8,93.9,94.0,94.1,94.3,94.4,94.6,94.7,94.9,95.0,95.2,95.3,95.4,95.6,95.7,95.8,96.0,96.1,96.2,96.7,96.9,97.0,97.1,97.3,97.4,97.7,97.8,97.9,98.1,98.2,98.4,98.5,98.8,98.9,100.0],\"y\":[30.64780889143394,30.33707211987298,30.317024586223884,30.28695328575024,30.276929518925694,30.156644317031127,29.956168980540184,29.946145213715635,29.545194540733746,29.404861805190087,29.364766737891898,29.354742971067353,29.234457769172785,29.18433893505005,29.154267634576406,29.084101266804577,29.054029966330933,28.823483329366347,28.793412028892707,28.78338826206816,28.753316961594518,28.743293194769972,28.703198127471783,28.302247454489894,28.041629517051668,28.021581983402573,28.011558216578024,28.00153444975348,27.911320548332554,27.85117794738527,27.821106646911627,27.740916512315252,27.730892745490703,27.710845211841608,27.700821445017063,27.63065507724523,27.620631310420684,27.610607543596135,27.60058377677159,27.580536243122495,27.550464942648855,27.52039364217521,27.440203507578836,27.360013372982458,27.26979947156153,27.24975193791244,27.23972817108789,27.09939543554423,27.089371668719682,27.039252834596947,27.0292290677724,26.92899139952693,26.87887256540419,26.818729964456907,26.778634897158717,26.708468529386888,26.688420995737793,26.588183327492324,26.427803058299567,26.417779291475018,26.357636690527734,26.34761292370319,26.257399022282264,26.20728018815953,26.16718512086134,26.12709005356315,26.01682861849313,25.676020546458524,25.635925479160335,25.565759111388505,25.55573534456396,25.54571157773941,25.50561651044122,25.495592743616676,25.48556897679213,25.325188707599374,25.315164940774828,25.27506987347664,25.244998573002995,25.144760904757526,25.08461830381024,25.054547003336598,25.01445193603841,24.974356868740223,24.813976599547466,24.783905299073822,24.773881532249277,24.743810231775637,24.723762698126542,24.703715164477448,24.673643864003804,24.62352502988107,24.61350126305652,24.413025926565577,24.40300215974103,24.312788258320104,24.30276449149556,24.272693191021915,24.26266942419737,24.142384222302802,24.11231292182916,24.102289155004613,24.052170320881878,24.042146554057332,23.9719801862855,23.961956419460954,23.951932652636405,23.90181381851367,23.881766284864575,23.79155238344365,23.761481082970008,23.671267181549084,23.65121964789999,23.611124580601803,23.591077046952705,23.58105328012816,23.530934446005425,23.480815611882687,23.47079184505814,23.320435342689933,23.270316508567195,23.230221441269006,23.19012637397082,23.15003130667263,23.089888705725347,23.029746104778063,22.99967480430442,22.92950843653259,22.839294535111666,22.75910440051529,22.74908063369074,22.7190093332171,22.658866732269814,22.628795431796174,22.618771664971625,22.58870036449799,22.50851022990161,22.49848646307706,22.46841516260342,22.408272561656137,22.398248794831588,22.378201261182493,22.368177494357948,22.348129960708853,22.32808242705976,22.28798735976157,22.267939826112475,22.187749691516096,22.17772592469155,22.117583323744267,22.097535790095172,22.077488256446077,22.06746448962153,22.057440722796983,22.037393189147892,21.997298121849703,21.937155520902415,21.917107987253324,21.88703668677968,21.836917852656946,21.796822785358756,21.78679901853421,21.74670395123602,21.736680184411476,21.726656417586923,21.706608883937832,21.696585117113283,21.67653758346419,21.656490049815098,21.626418749341454,21.61639498251691,21.57629991521872,21.56627614839417,21.556252381569625,21.53620484792053,21.52618108109598,21.516157314271435,21.506133547446886,21.486086013797795,21.476062246973246,21.45601471332415,21.445990946499606,21.425943412850508,21.415919646025962,21.395872112376868,21.385848345552322,21.375824578727773,21.355777045078682,21.34575327825413,21.335729511429584,21.315681977780493,21.305658210955944,21.295634444131395,21.24551561000866,21.225468076359565,21.215444309535016,21.20542054271047,21.18537300906138,21.175349242236827,21.14527794176319,21.13525417493864,21.125230408114092,21.105182874465,21.095159107640452,21.075111573991357,21.06508780716681,21.035016506693168,21.024992739868622,20.9147313047986],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[4.09,4.9671,4.9671,6.0622,6.0622,6.0622,5.5605,5.9505,6.0821,6.5921,6.3467,6.2267,5.4509,4.7075,4.4619,4.4986,4.4986,4.2579,3.7965,3.7965,3.7979,4.0123,3.9769,4.0952,4.3996,4.4546,4.682,4.4534,4.4547,4.239,4.233,4.175,3.99,3.7872,3.7598,3.3603,3.3779,3.9342,3.8473,5.4011,5.4011,5.7209,5.7209,5.7209,5.7209,5.1004,5.1004,5.6894,5.87,6.0877,6.8147,6.8147,6.8147,6.8147,7.3197,8.6966,9.1876,8.3248,7.8148,6.932,7.2254,6.8185,7.2255,7.9809,9.2229,6.6115,6.6115,6.498,6.498,6.498,5.2873,5.2873,5.2873,5.2873,4.2515,4.5026,4.0522,4.0905,5.0141,4.5026,5.4007,5.4007,5.4007,5.4007,4.7794,4.4377,4.4272,3.7476,3.4217,3.4145,3.0923,3.0921,3.6659,3.6659,3.615,3.4952,3.4952,3.4952,3.4952,3.4952,2.7778,2.8561,2.7147,2.7147,2.421,2.1069,2.211,2.1224,2.4329,2.5451,2.7778,2.6775,2.3534,2.548,2.2565,2.4631,2.7301,2.7474,2.4775,2.7592,2.2577,2.1974,2.0869,1.9444,2.0063,1.9929,1.7572,1.7883,1.8125,1.9799,2.1185,2.271,2.3274,2.4699,2.346,2.1107,1.9669,1.8498,1.6686,1.6687,1.6119,1.4394,1.3216,1.4118,1.3459,1.4191,1.5166,1.4608,1.5296,1.5257,1.618,1.5916,1.6102,1.6232,1.7494,1.7455,1.7364,1.8773,1.7573,1.7659,1.7984,1.9709,2.0407,2.162,2.422,2.2834,2.0459,2.4259,2.1,2.2625,2.4259,2.3887,2.5961,2.6463,2.7019,3.1323,3.5549,3.3175,2.9153,2.829,2.741,2.5979,2.7006,2.847,2.9879,3.2797,3.1992,3.7886,4.5667,4.5667,6.4798,6.4798,6.4798,6.2196,6.2196,5.6484,7.309,7.309,7.309,7.6534,7.6534,6.27,6.27,5.118,5.118,3.9454,4.3549,4.3549,4.2392,3.875,3.8771,3.665,3.6526,3.9454,3.5875,3.9454,3.1121,3.4211,2.8893,3.3633,2.8617,3.048,3.2721,3.2721,2.8944,2.8944,3.2157,3.2157,3.3751,3.3751,3.6715,3.6715,3.8384,3.6519,3.6519,3.6519,4.148,4.148,6.1899,6.1899,6.3361,6.3361,7.0355,7.0355,7.9549,7.9549,8.0555,8.0555,7.8265,7.8265],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[1.3216,1.3459,1.4118,1.4191,1.4394,1.4608,1.5166,1.5257,1.5296,1.5916,1.6102,1.6119,1.618,1.6232,1.6686,1.6687,1.7364,1.7455,1.7494,1.7572,1.7573,1.7659,1.7883,1.7984,1.8125,1.8498,1.8773,1.9444,1.9669,1.9709,1.9799,1.9929,2.0063,2.0407,2.0459,2.0869,2.1,2.1069,2.1107,2.1185,2.1224,2.162,2.1974,2.211,2.2565,2.2577,2.2625,2.271,2.2834,2.3274,2.346,2.3534,2.3887,2.421,2.422,2.4259,2.4329,2.4631,2.4699,2.4775,2.5451,2.548,2.5961,2.5979,2.6463,2.6775,2.7006,2.7019,2.7147,2.7301,2.741,2.7474,2.7592,2.7778,2.829,2.847,2.8561,2.8617,2.8893,2.8944,2.9153,2.9879,3.048,3.0921,3.0923,3.1121,3.1323,3.1992,3.2157,3.2721,3.2797,3.3175,3.3603,3.3633,3.3751,3.3779,3.4145,3.4211,3.4217,3.4952,3.5549,3.5875,3.615,3.6519,3.6526,3.665,3.6659,3.6715,3.7476,3.7598,3.7872,3.7886,3.7965,3.7979,3.8384,3.8473,3.875,3.8771,3.9342,3.9454,3.9769,3.99,4.0123,4.0522,4.09,4.0905,4.0952,4.148,4.175,4.233,4.239,4.2392,4.2515,4.2579,4.3549,4.3996,4.4272,4.4377,4.4534,4.4546,4.4547,4.4619,4.4986,4.5026,4.5667,4.682,4.7075,4.7794,4.9671,5.0141,5.1004,5.118,5.2873,5.4007,5.4011,5.4509,5.5605,5.6484,5.6894,5.7209,5.87,5.9505,6.0622,6.0821,6.0877,6.1899,6.2196,6.2267,6.27,6.3361,6.3467,6.4798,6.498,6.5921,6.6115,6.8147,6.8185,6.932,7.0355,7.2254,7.2255,7.309,7.3197,7.6534,7.8148,7.8265,7.9549,7.9809,8.0555,8.3248,8.6966,9.1876,9.2229],\"y\":[22.657575154380453,22.671771064564734,22.710269438274377,22.71453405326801,22.726393188113317,22.73889493617684,22.771492952155565,22.776809116051737,22.77908747200724,22.81530748976138,22.826173495087623,22.827166624606686,22.830730206998627,22.833768014939295,22.860290415036683,22.860348834420158,22.89989875703234,22.90521492092851,22.90749327688401,22.91204998879502,22.91210840817849,22.917132475157292,22.93021841705556,22.93611877478648,22.94435590785637,22.96614633789233,22.982211668347794,23.021411074659127,23.03455543594087,23.03689221127985,23.042149955792546,23.04974447564422,23.057572673029792,23.077668940944992,23.08070674888566,23.104658696110175,23.11231163534532,23.116342572805056,23.118562509377085,23.12311922128809,23.125397577243593,23.14853165309946,23.169212114849405,23.177157151001925,23.203737970482788,23.20443900308448,23.207243133491254,23.212208781086577,23.219452784637404,23.24515731336615,23.256023318692392,23.260346353069497,23.280968395435966,23.299837856298204,23.300422050132948,23.30270040608845,23.30678976293166,23.324432416740933,23.328404934817193,23.33284480796125,23.372336311189958,23.374030473310714,23.40213019676191,23.40318174566445,23.43145672726607,23.449683574910086,23.463178452492677,23.463937904477845,23.47141558556257,23.48041217061763,23.486779883416343,23.490518723958704,23.497412211208687,23.50827821653493,23.53818894087383,23.548704429899225,23.554020593795396,23.557292079269963,23.573415829108903,23.5763952176661,23.588604868812254,23.63101734121468,23.666127390682806,23.691890338795023,23.692007177561972,23.70357421548991,23.71537493095174,23.754457498496127,23.764096696769407,23.797045229048976,23.801485102193034,23.823567629146364,23.848571125273413,23.850323706777647,23.857217194027626,23.85885293676491,23.88023443111655,23.88409011042586,23.884440626726708,23.927378873580405,23.962255245514633,23.98129996452729,23.997365294982757,24.018922047484818,24.019330983169137,24.026574986719964,24.027100761171237,24.030372246645804,24.074829397469834,24.081956562253716,24.097963473325706,24.09878134469435,24.103396475988827,24.10421434735747,24.127874197664607,24.13307352279383,24.149255692016244,24.150482499069206,24.1838399670331,24.190382937982235,24.208785043776675,24.216437983011826,24.22946550552662,24.252774839532915,24.274857366486245,24.275149463403615,24.277895174426913,24.308740608901406,24.324513842439497,24.358397084854662,24.361902247863128,24.362019086630074,24.36920467079743,24.37294351133979,24.429610313309976,24.455723777723044,24.47184752756198,24.477981562826795,24.487153406032277,24.48785443863397,24.487912858017445,24.492119053627604,24.513558967362716,24.515895742701694,24.553342567508793,24.6207001166548,24.635597059440776,24.677600596158882,24.787253778940364,24.81471088917334,24.865126817111765,24.87540862860326,24.974312644825453,25.040560225685443,25.04079390321934,25.0698867561896,25.13391440047756,25.185265038551577,25.209216985776088,25.227619091570528,25.314722392330886,25.361749996027793,25.427004447368716,25.438629904680127,25.441901390154694,25.50160600006555,25.518956556957452,25.523104333184136,25.54839992622856,25.587015138705148,25.593207593353437,25.670963792757888,25.681596120550232,25.73656876039966,25.747902120793697,25.866610308013716,25.86883024458574,25.93513624482921,25.99560030672523,26.10653871594315,26.106597135326624,26.155377320527762,26.161628194559526,26.35657367721366,26.45086256214137,26.45769763000788,26.53270811838903,26.54789715809238,26.591478018164295,26.748801417860903,26.96600468561879,27.252843858478183,27.273465900844652],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[1.0,2.0,2.0,3.0,3.0,3.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,4.0,4.0,4.0,4.0,3.0,5.0,2.0,5.0,8.0,8.0,8.0,8.0,8.0,8.0,3.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,3.0,3.0,3.0,3.0,2.0,2.0,2.0,2.0,4.0,4.0,4.0,2.0,2.0,2.0,2.0,2.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,5.0,5.0,5.0,5.0,5.0,5.0,1.0,1.0,4.0,2.0,2.0,2.0,3.0,3.0,2.0,2.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,6.0,6.0,6.0,6.0,6.0,6.0,7.0,7.0,7.0,7.0,7.0,7.0],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0],\"y\":[23.644651434980865,23.8254626807442,24.006273926507532,24.187085172270866,24.3678964180342,24.548707663797533,24.729518909560866,24.9103301553242],\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[296.0,242.0,242.0,222.0,222.0,222.0,311.0,311.0,311.0,311.0,311.0,311.0,311.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,279.0,279.0,279.0,279.0,252.0,252.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,233.0,243.0,243.0,243.0,243.0,469.0,226.0,313.0,256.0,284.0,284.0,284.0,284.0,284.0,284.0,216.0,337.0,337.0,345.0,345.0,345.0,305.0,305.0,305.0,305.0,398.0,398.0,398.0,398.0,398.0,398.0,281.0,281.0,281.0,281.0,247.0,247.0,247.0,247.0,270.0,270.0,270.0,270.0,270.0,270.0,270.0,276.0,276.0,276.0,276.0,276.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,384.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,432.0,188.0,188.0,188.0,188.0,188.0,188.0,188.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,437.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,403.0,296.0,296.0,296.0,296.0,296.0,296.0,296.0,193.0,193.0,193.0,193.0,193.0,193.0,193.0,193.0,398.0,398.0,398.0,398.0,398.0,398.0,265.0,265.0,255.0,329.0,329.0,329.0,402.0,402.0,348.0,348.0,224.0,224.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,277.0,276.0,276.0,276.0,276.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,307.0,300.0,300.0,300.0,300.0,300.0,300.0,330.0,330.0,330.0,330.0,330.0,330.0],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[188.0,193.0,216.0,222.0,224.0,226.0,233.0,242.0,243.0,247.0,252.0,255.0,256.0,265.0,270.0,276.0,277.0,279.0,281.0,284.0,296.0,300.0,305.0,307.0,311.0,313.0,329.0,330.0,337.0,345.0,348.0,384.0,398.0,402.0,403.0,432.0,437.0,469.0],\"y\":[27.994786990570176,27.85508624852239,27.212462835102563,27.044821944645218,26.988941647826103,26.933061351006987,26.737480312140086,26.486018976454066,26.45807882804451,26.34631823440628,26.20661749235849,26.12279704712982,26.09485689872026,25.843395563034242,25.703694820986456,25.53605393052911,25.50811378211955,25.452233485300436,25.39635318848132,25.31253274325265,24.97725096233796,24.865490368699728,24.725789626651938,24.669909329832826,24.558148736194596,24.502268439375477,24.055226064822556,24.027285916413,23.8317048775461,23.608183690269637,23.524363245040966,22.518517902296892,22.127355824563086,22.015595230924855,21.987655082515296,21.177390778638127,21.03769003659034,20.143605287484498],\"type\":\"scatter\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[15.3,17.8,17.8,18.7,18.7,18.7,15.2,15.2,15.2,15.2,15.2,15.2,15.2,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,21.0,19.2,19.2,19.2,19.2,18.3,18.3,17.9,17.9,17.9,17.9,17.9,17.9,17.9,17.9,17.9,16.8,16.8,16.8,16.8,21.1,17.9,17.3,15.1,19.7,19.7,19.7,19.7,19.7,19.7,18.6,16.1,16.1,18.9,18.9,18.9,19.2,19.2,19.2,19.2,18.7,18.7,18.7,18.7,18.7,18.7,19.0,19.0,19.0,19.0,18.5,18.5,18.5,18.5,17.8,17.8,17.8,17.8,18.2,18.2,18.2,18.0,18.0,18.0,18.0,18.0,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,20.9,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,19.1,19.1,19.1,19.1,19.1,19.1,19.1,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,21.2,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,14.7,16.6,16.6,16.6,16.6,16.6,16.6,16.6,17.8,17.8,17.8,17.8,17.8,17.8,17.8,17.8,15.2,15.2,15.2,15.2,15.2,15.2,15.6,15.6,14.4,12.6,12.6,12.6,17.0,17.0,14.7,14.7,14.7,14.7,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,18.6,16.4,16.4,16.4,16.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,17.4,16.6,16.6,16.6,16.6,16.6,16.6,19.1,19.1,19.1,19.1,19.1,19.1],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x11\",\"yaxis\":\"y11\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[12.6,14.4,14.7,15.1,15.2,15.3,15.6,16.1,16.4,16.6,16.8,17.0,17.3,17.4,17.8,17.9,18.0,18.2,18.3,18.5,18.6,18.7,18.9,19.0,19.1,19.2,19.7,20.9,21.0,21.1,21.2],\"y\":[31.926396775838622,29.33164911541356,28.89919117200938,28.32258058080381,28.178427933002418,28.034275285201023,27.60181734179685,26.881054102789882,26.44859615938571,26.16029086378292,25.871985568180136,25.58368027257735,25.151222329173173,25.007069681371785,24.43045909016621,24.286306442364822,24.142153794563427,23.85384849896064,23.70969585115925,23.421390555556464,23.27723790775507,23.13308525995368,22.844779964350895,22.7006273165495,22.556474668748105,22.412322020946718,21.691558781939754,19.961727008323045,19.81757436052165,19.673421712720256,19.529269064918868],\"type\":\"scatter\",\"xaxis\":\"x11\",\"yaxis\":\"y11\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[396.9,396.9,392.83,394.63,396.9,394.12,395.6,396.9,386.63,386.71,392.52,396.9,390.5,396.9,380.02,395.62,386.85,386.75,288.99,390.95,376.57,392.53,396.9,394.54,394.33,303.42,376.88,306.38,387.94,380.23,360.17,376.73,232.6,358.77,248.31,396.9,377.56,396.9,393.43,395.63,395.62,385.41,383.37,394.46,389.39,396.9,396.9,392.74,396.9,396.9,395.56,393.97,396.9,396.9,396.9,395.93,396.9,392.9,390.68,396.9,395.11,378.08,396.9,395.58,393.24,396.9,396.9,396.21,396.9,396.9,383.73,376.94,390.91,377.17,394.92,383.23,373.66,386.96,386.4,396.06,396.9,395.63,396.9,390.64,396.9,392.3,395.99,395.15,396.9,396.06,392.18,393.55,395.01,396.33,396.9,357.98,391.83,396.9,393.53,396.9,394.76,395.58,70.8,394.47,392.69,394.05,395.67,387.69,395.24,391.23,393.49,395.59,394.95,396.9,388.74,344.91,393.3,394.51,338.63,391.5,389.15,377.67,378.09,370.31,379.38,385.02,359.29,392.11,396.9,396.9,395.04,396.9,385.76,388.69,262.76,394.67,378.25,394.08,392.04,396.9,388.08,396.9,396.9,396.9,396.9,172.91,169.27,391.71,356.99,351.85,372.8,341.6,343.28,261.95,321.02,88.01,88.63,363.43,353.89,364.31,338.92,374.43,389.61,388.45,395.11,240.16,369.3,227.61,297.09,330.04,292.29,348.13,396.9,395.5,393.23,390.96,393.23,395.6,391.27,396.9,395.56,396.9,394.12,396.9,391.0,387.11,392.63,393.87,382.84,396.9,377.68,389.71,390.49,393.37,376.7,394.23,396.9,354.31,392.2,396.9,384.3,393.77,395.38,392.78,390.55,396.9,394.87,389.43,381.32,396.9,393.25,395.24,390.94,385.81,348.93,393.63,392.8,392.78,396.9,393.74,391.7,395.24,390.39,396.9,385.05,382.0,387.38,372.08,377.51,380.34,378.35,376.14,385.91,378.95,360.2,376.75,388.45,390.07,379.41,383.78,391.25,394.62,372.75,374.71,372.49,389.13,390.18,376.14,374.71,393.74],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x12\",\"yaxis\":\"y12\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[70.8,88.01,88.63,169.27,172.91,227.61,232.6,240.16,248.31,261.95,262.76,288.99,292.29,297.09,303.42,306.38,321.02,330.04,338.63,338.92,341.6,343.28,344.91,348.13,348.93,351.85,353.89,354.31,356.99,357.98,358.77,359.29,360.17,360.2,363.43,364.31,369.3,370.31,372.08,372.49,372.75,372.8,373.66,374.43,374.71,376.14,376.57,376.7,376.73,376.75,376.88,376.94,377.17,377.51,377.56,377.67,377.68,378.08,378.09,378.25,378.35,378.95,379.38,379.41,380.02,380.23,380.34,381.32,382.0,382.84,383.23,383.37,383.73,383.78,384.3,385.02,385.05,385.41,385.76,385.81,385.91,386.4,386.63,386.71,386.75,386.85,386.96,387.11,387.38,387.69,387.94,388.08,388.45,388.69,388.74,389.13,389.15,389.39,389.43,389.61,389.71,390.07,390.18,390.39,390.49,390.5,390.55,390.64,390.68,390.91,390.94,390.95,390.96,391.0,391.23,391.25,391.27,391.5,391.7,391.71,391.83,392.04,392.11,392.18,392.2,392.3,392.52,392.53,392.63,392.69,392.74,392.78,392.8,392.83,392.9,393.23,393.24,393.25,393.3,393.37,393.43,393.49,393.53,393.55,393.63,393.74,393.77,393.87,393.97,394.05,394.08,394.12,394.23,394.33,394.46,394.47,394.51,394.54,394.62,394.63,394.67,394.76,394.87,394.92,394.95,395.01,395.04,395.11,395.15,395.24,395.38,395.5,395.56,395.58,395.59,395.6,395.62,395.63,395.67,395.93,395.99,396.06,396.21,396.33,396.9],\"y\":[12.54684131679314,13.207619824639107,13.231424744735822,16.327600158605588,16.467358076592763,18.567566349641822,18.75915756138798,19.049424006438272,19.362343520612857,19.886051762740628,19.91715173899602,20.9242534392168,21.0509570461832,21.235253201770682,21.47829375695168,21.591943052897296,22.154046327439126,22.500369519813944,22.830182848250715,22.841317407650795,22.944216094520478,23.00871974897609,23.071303651811014,23.194935656184285,23.225651682115533,23.337765176764584,23.416091042889267,23.432216956503172,23.53511564337285,23.57312672546277,23.603458801069877,23.62342421792519,23.657211846449563,23.658363697421983,23.782379652119396,23.816167280643768,24.007758492389925,24.046537475128126,24.11449668250101,24.130238645790776,24.140221354218433,24.142141105839134,24.175160833715225,24.204725008674053,24.215475617749988,24.270380514102094,24.286890378040138,24.291881732253966,24.29303358322639,24.293801483874667,24.298792838088495,24.301096540033342,24.309927397488572,24.322981708509353,24.324901460130057,24.329124913695605,24.329508864019743,24.344866876985368,24.345250827309506,24.351394032495758,24.355233535737163,24.3782705551856,24.394780419123645,24.39593227009607,24.41935323986864,24.427416196675598,24.43163965024114,24.46926678200692,24.49537540404848,24.52762723127629,24.542601293917777,24.547976598455744,24.561798810124806,24.563718561745507,24.583683978600817,24.61132840193894,24.612480252911364,24.626302464580426,24.639740725925343,24.641660477546047,24.645499980787456,24.664313546670343,24.67314440412558,24.676216006718704,24.677751808015266,24.68159131125667,24.68581476482222,24.691574019684325,24.701940678436124,24.713843138484478,24.723441896587996,24.728817201125963,24.743023363119164,24.75223817089854,24.754157922519244,24.769131985160726,24.769899885809007,24.779114693588383,24.780650494884945,24.787561600719478,24.79140110396088,24.80522331562994,24.80944676919549,24.81750972600244,24.82134922924385,24.821733179567985,24.82365293118869,24.827108484105956,24.828644285402518,24.837475142857755,24.838626993830175,24.839010944154314,24.839394894478453,24.840930695775018,24.849761553230252,24.850529453878533,24.851297354526814,24.860128211982047,24.86780721846486,24.868191168789,24.872798572678686,24.880861529485642,24.883549181754624,24.886236834023606,24.88700473467189,24.890844237913296,24.899291145044387,24.89967509536853,24.903514598609934,24.905818300554778,24.907738052175482,24.909273853472044,24.910041754120325,24.91119360509275,24.91388125736173,24.92655161805837,24.92693556838251,24.927319518706653,24.929239270327358,24.93192692259634,24.934230624541183,24.936534326486026,24.938070127782588,24.938838028430872,24.941909631023996,24.94613308458954,24.94728493556196,24.95112443880337,24.954963942044778,24.9580355446379,24.95918739561032,24.960723196906883,24.96494665047243,24.968786153713836,24.973777507927664,24.974161458251807,24.97569725954837,24.97684911052079,24.979920713113913,24.980304663438055,24.981840464734617,24.985296017651883,24.989519471217427,24.99143922283813,24.99259107381055,24.994894775755398,24.996046626727818,24.998734278996803,25.00027008029336,25.003725633210628,25.0091009377486,25.013708341638285,25.01601204358313,25.01677994423141,25.01716389455555,25.017547844879694,25.01831574552797,25.018699695852114,25.020235497148676,25.030218205576332,25.032521907521176,25.03520955979016,25.040968814652267,25.045576218541953,25.067461387017968],\"type\":\"scatter\",\"xaxis\":\"x12\",\"yaxis\":\"y12\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[4.98,9.14,4.03,2.94,5.33,5.21,12.43,19.15,29.93,17.1,20.45,13.27,15.71,8.26,10.26,8.47,6.58,14.67,11.69,11.28,21.02,13.83,18.72,19.88,16.3,16.51,14.81,17.28,12.8,11.98,22.6,13.04,27.71,18.35,20.34,9.68,11.41,8.77,10.13,4.32,1.98,4.84,5.81,7.44,9.55,10.21,14.15,18.8,30.81,16.2,13.45,9.43,5.28,8.43,14.8,4.81,5.77,3.95,6.86,9.22,13.15,14.44,6.73,9.5,8.05,4.67,10.24,8.1,13.09,8.79,6.72,9.88,5.52,7.54,6.78,8.94,11.97,10.27,12.34,9.1,5.29,7.22,6.72,7.51,9.62,6.53,12.86,8.44,5.5,5.7,8.81,8.2,8.16,6.21,10.59,6.65,11.34,4.21,3.57,6.19,9.42,7.67,10.63,13.44,12.33,16.47,18.66,14.09,12.27,15.55,13.0,10.16,16.21,17.09,10.45,15.76,12.04,10.3,15.37,13.61,14.37,14.27,17.93,25.41,17.58,14.81,27.26,17.19,15.39,18.34,12.6,12.26,11.12,15.03,17.31,16.96,16.9,14.59,21.32,18.46,24.16,34.41,26.82,26.42,29.29,27.8,16.65,29.53,28.32,21.45,14.1,13.28,12.12,15.79,15.12,15.02,16.14,4.59,6.43,7.39,5.5,1.73,1.92,3.32,11.64,9.81,3.7,12.14,11.1,11.32,14.43,12.03,14.69,9.04,9.64,5.33,10.11,6.29,6.92,5.04,7.56,9.45,4.82,5.68,13.98,13.15,4.45,6.68,4.56,5.39,5.1,4.69,2.87,5.03,4.38,2.97,4.08,8.61,6.62,4.56,4.45,7.43,3.11,3.81,2.88,10.87,10.97,18.06,14.66,23.09,17.27,23.98,16.03,9.38,29.55,9.47,13.51,9.69,17.92,10.5,9.71,21.46,9.93,7.6,4.14,4.63,3.13,6.36,3.92,3.76,11.65,5.25,2.47,3.95,8.05,10.88,9.54,4.73,6.36,7.37,11.38,12.4,11.22,5.19,12.5,18.46,9.16,10.15,9.52,6.56],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x13\",\"yaxis\":\"y13\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[1.73,1.92,1.98,2.47,2.87,2.88,2.94,2.97,3.11,3.13,3.32,3.57,3.7,3.76,3.81,3.92,3.95,4.03,4.08,4.14,4.21,4.32,4.38,4.45,4.56,4.59,4.63,4.67,4.69,4.73,4.81,4.82,4.84,4.98,5.03,5.04,5.1,5.19,5.21,5.25,5.28,5.29,5.33,5.39,5.5,5.52,5.68,5.7,5.77,5.81,6.19,6.21,6.29,6.36,6.43,6.53,6.56,6.58,6.62,6.65,6.68,6.72,6.73,6.78,6.86,6.92,7.22,7.37,7.39,7.43,7.44,7.51,7.54,7.56,7.6,7.67,8.05,8.1,8.16,8.2,8.26,8.43,8.44,8.47,8.61,8.77,8.79,8.81,8.94,9.04,9.1,9.14,9.16,9.22,9.38,9.42,9.43,9.45,9.47,9.5,9.52,9.54,9.55,9.62,9.64,9.68,9.69,9.71,9.81,9.88,9.93,10.11,10.13,10.15,10.16,10.21,10.24,10.26,10.27,10.3,10.45,10.5,10.59,10.63,10.87,10.88,10.97,11.1,11.12,11.22,11.28,11.32,11.34,11.38,11.41,11.64,11.65,11.69,11.97,11.98,12.03,12.04,12.12,12.14,12.26,12.27,12.33,12.34,12.4,12.43,12.5,12.6,12.8,12.86,13.0,13.04,13.09,13.15,13.27,13.28,13.44,13.45,13.51,13.61,13.83,13.98,14.09,14.1,14.15,14.27,14.37,14.43,14.44,14.59,14.66,14.67,14.69,14.8,14.81,15.02,15.03,15.12,15.37,15.39,15.55,15.71,15.76,15.79,16.03,16.14,16.2,16.21,16.3,16.47,16.51,16.65,16.9,16.96,17.09,17.1,17.19,17.27,17.28,17.31,17.58,17.92,17.93,18.06,18.34,18.35,18.46,18.66,18.72,18.8,19.15,19.88,20.34,20.45,21.02,21.32,21.45,21.46,22.6,23.09,23.98,24.16,25.41,26.42,26.82,27.26,27.71,27.8,28.32,29.29,29.53,29.55,29.93,30.81,34.41],\"y\":[33.37430970198619,33.196737575122995,33.140662166639885,32.68271299736112,32.30887694080704,32.29953103939318,32.24345563091007,32.215417926668515,32.084575306874584,32.06588350404688,31.888311377183687,31.65466384183738,31.5331671234573,31.477091714974186,31.430362207904928,31.32755729235255,31.299519588110996,31.224752376800176,31.178022869730917,31.121947461247803,31.056526151350837,30.95372123579846,30.89764582731535,30.832224517418382,30.72941960186601,30.70138189762445,30.663998291969044,30.626614686313633,30.60792288348593,30.57053927783052,30.495772066519706,30.48642616510585,30.467734362278147,30.336891742484216,30.290162235414954,30.280816334001102,30.224740925517988,30.14062781279332,30.121936009965616,30.084552404310205,30.056514700068647,30.047168798654795,30.009785192999388,29.953709784516274,29.8509048689639,29.832213066136195,29.68267864351456,29.663986840686853,29.59856553078989,29.56118192513448,29.206037671408097,29.18734586858039,29.112578657269573,29.047157347372607,28.981736037475642,28.88827702333712,28.860239319095562,28.84154751626786,28.804163910612452,28.776126206370893,28.748088502129338,28.710704896473928,28.701358995060076,28.654629487990814,28.579862276679997,28.523786868196883,28.243409825781317,28.103221304573534,28.084529501745827,28.04714589609042,28.03779999467657,27.972378684779603,27.944340980538044,27.92564917771034,27.888265572054934,27.822844262157965,27.46770000843158,27.42097050136232,27.36489509287921,27.3275114872238,27.271436078740685,27.1125557547052,27.103209853291347,27.075172149049788,26.944329529255857,26.794795106634222,26.776103303806515,26.75741150097881,26.635914782598732,26.54245576846021,26.486380359977097,26.44899675432169,26.430304951493984,26.37422954301087,26.224695120389235,26.18731151473383,26.177965613319977,26.15927381049227,26.140582007664563,26.112544303423007,26.093852500595304,26.0751606977676,26.06581479635375,26.000393486456783,25.981701683629076,25.94431807797367,25.934972176559818,25.91628037373211,25.82282135959359,25.75740004969662,25.710670542627362,25.542444317178024,25.523752514350317,25.505060711522614,25.495714810108762,25.4489853030395,25.420947598797945,25.40225579597024,25.39290989455639,25.364872190314827,25.224683669107048,25.177954162037786,25.093841049313117,25.056457443657706,24.832155809725254,24.8228099083114,24.73869679558673,24.617200077206654,24.59850827437895,24.505049260240426,24.448973851757312,24.411590246101902,24.3928984432742,24.35551483761879,24.327477133377233,24.112521400858633,24.10317549944478,24.06579189378937,23.804106654201508,23.794760752787656,23.748031245718394,23.738685344304542,23.663918132993725,23.645226330166018,23.533075513199794,23.523729611785942,23.46765420330283,23.458308301888977,23.402232893405863,23.374195189164304,23.308773879267342,23.215314865128818,23.028396836851773,22.97232142836866,22.841478808574728,22.80409520291932,22.75736569585006,22.701290287366945,22.589139470400717,22.579793568986865,22.43025914636523,22.42091324495138,22.364837836468265,22.271378822329744,22.065768991224992,21.92558047001721,21.822775554464837,21.81342965305098,21.766700145981723,21.654549329015495,21.561090314876974,21.50501490639386,21.49566900498001,21.355480483772226,21.290059173875257,21.280713272461405,21.2620214696337,21.159216554081326,21.149870652667474,20.95360672297658,20.94426082156273,20.860147708838056,20.62650017349175,20.607808370664046,20.45827394804241,20.308739525420776,20.262010018351514,20.233972314109955,20.009670680177503,19.90686576462513,19.850790356142017,19.841444454728162,19.757331342003493,19.598451017968006,19.561067412312596,19.430224792518665,19.19657725717236,19.140501848689247,19.019005130309168,19.009659228895316,18.925546116170644,18.850778904859826,18.841433003445974,18.81339529920442,18.56105596103041,18.243295312959432,18.23394941154558,18.1124526931655,17.85076745357764,17.841421552163787,17.73861663661141,17.551698608334366,17.495623199851256,17.420855988540435,17.09374943905561,16.411498635844396,15.981587170807195,15.87878225525482,15.346065874665243,15.065688832249673,14.944192113869597,14.934846212455742,13.86941345127659,13.41146428199783,12.57967905616498,12.411452830715643,11.243215153984114,10.299279111185037,9.92544305463095,9.51422339242145,9.0936578287981,9.009544716073432,8.523557842553114,7.617005405409451,7.392703771476995,7.374011968649292,7.018867714922909,6.196428390503911,2.831903881517114],\"type\":\"scatter\",\"xaxis\":\"x13\",\"yaxis\":\"y13\"},{\"marker\":{\"size\":3},\"mode\":\"markers\",\"x\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2],\"type\":\"scattergl\",\"xaxis\":\"x14\",\"yaxis\":\"y14\"},{\"line\":{\"color\":\"red\",\"width\":1},\"x\":[11.8,12.7,13.1,13.2,13.3,13.4,13.5,13.6,13.8,13.9,14.0,14.3,14.4,14.5,14.6,14.8,15.0,15.2,15.3,15.4,15.6,15.7,16.0,16.2,16.5,16.6,17.0,17.1,17.3,17.4,17.5,17.6,17.8,18.0,18.1,18.2,18.3,18.4,18.5,18.6,18.7,18.8,18.9,19.1,19.2,19.3,19.4,19.5,19.6,19.7,19.8,19.9,20.0,20.1,20.2,20.3,20.4,20.5,20.6,20.8,20.9,21.0,21.2,21.4,21.5,21.6,21.7,22.0,22.2,22.3,22.4,22.5,22.6,22.7,22.8,22.9,23.0,23.1,23.2,23.3,23.4,23.5,23.6,23.7,23.8,23.9,24.0,24.1,24.2,24.3,24.4,24.5,24.6,24.7,24.8,25.0,25.1,25.3,26.2,26.4,26.5,26.6,26.7,27.0,27.1,27.5,28.0,28.1,28.4,28.7,29.0,29.1,29.4,29.6,29.8,29.9,30.1,30.3,30.5,30.8,31.1,31.5,31.6,31.7,32.0,32.5,32.9,33.0,33.2,33.3,33.4,34.6,34.7,34.9,35.4,36.2,36.4,37.0,37.2,37.6,37.9,38.7,39.8,41.3,41.7,42.3,43.8,44.8,46.7,48.3,48.5,50.0],\"y\":[11.799999999999995,12.699999999999994,13.099999999999994,13.199999999999994,13.299999999999995,13.399999999999993,13.499999999999993,13.599999999999993,13.799999999999994,13.899999999999993,13.999999999999993,14.299999999999994,14.399999999999993,14.499999999999993,14.599999999999993,14.799999999999994,14.999999999999993,15.199999999999992,15.299999999999994,15.399999999999993,15.599999999999993,15.699999999999992,15.999999999999993,16.199999999999992,16.499999999999993,16.599999999999994,16.999999999999993,17.099999999999994,17.299999999999994,17.39999999999999,17.499999999999993,17.599999999999994,17.799999999999994,17.999999999999993,18.099999999999994,18.199999999999992,18.299999999999994,18.39999999999999,18.499999999999993,18.599999999999994,18.699999999999992,18.799999999999994,18.89999999999999,19.099999999999994,19.199999999999992,19.299999999999994,19.39999999999999,19.499999999999993,19.599999999999994,19.699999999999992,19.799999999999994,19.89999999999999,19.999999999999993,20.099999999999994,20.199999999999992,20.299999999999994,20.39999999999999,20.499999999999993,20.599999999999994,20.799999999999994,20.89999999999999,20.999999999999993,21.199999999999992,21.39999999999999,21.499999999999993,21.599999999999994,21.699999999999992,21.999999999999993,22.199999999999992,22.299999999999994,22.39999999999999,22.499999999999993,22.599999999999994,22.699999999999992,22.799999999999994,22.89999999999999,22.999999999999993,23.099999999999994,23.199999999999992,23.299999999999994,23.39999999999999,23.499999999999993,23.599999999999994,23.699999999999992,23.799999999999994,23.89999999999999,23.999999999999993,24.099999999999994,24.199999999999992,24.299999999999994,24.39999999999999,24.499999999999993,24.599999999999994,24.699999999999992,24.799999999999994,24.999999999999993,25.099999999999994,25.299999999999994,26.199999999999992,26.39999999999999,26.499999999999993,26.599999999999994,26.69999999999999,26.99999999999999,27.09999999999999,27.49999999999999,27.99999999999999,28.09999999999999,28.399999999999988,28.69999999999999,28.99999999999999,29.09999999999999,29.399999999999988,29.59999999999999,29.79999999999999,29.899999999999988,30.09999999999999,30.29999999999999,30.49999999999999,30.79999999999999,31.09999999999999,31.49999999999999,31.59999999999999,31.69999999999999,31.99999999999999,32.499999999999986,32.899999999999984,32.999999999999986,33.19999999999999,33.29999999999998,33.399999999999984,34.59999999999999,34.69999999999999,34.899999999999984,35.399999999999984,36.19999999999999,36.399999999999984,36.999999999999986,37.19999999999999,37.59999999999999,37.899999999999984,38.69999999999999,39.79999999999998,41.29999999999998,41.69999999999999,42.29999999999998,43.79999999999998,44.79999999999998,46.69999999999999,48.29999999999998,48.499999999999986,49.999999999999986],\"type\":\"scatter\",\"xaxis\":\"x14\",\"yaxis\":\"y14\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2888888888888889]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.88,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.88,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.7111111111111111,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.88,1.0]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,0.2888888888888889]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.66,0.78]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.66,0.78]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.7111111111111111,1.0]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.66,0.78]},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.0,0.2888888888888889]},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.44,0.56]},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.44,0.56]},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.7111111111111111,1.0]},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.44,0.56]},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.0,0.2888888888888889]},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.22,0.33999999999999997]},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.22,0.33999999999999997]},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.7111111111111111,1.0]},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.22,0.33999999999999997]},\"xaxis13\":{\"anchor\":\"y13\",\"domain\":[0.0,0.2888888888888889]},\"yaxis13\":{\"anchor\":\"x13\",\"domain\":[0.0,0.12]},\"xaxis14\":{\"anchor\":\"y14\",\"domain\":[0.35555555555555557,0.6444444444444445]},\"yaxis14\":{\"anchor\":\"x14\",\"domain\":[0.0,0.12]},\"xaxis15\":{\"anchor\":\"y15\",\"domain\":[0.7111111111111111,1.0]},\"yaxis15\":{\"anchor\":\"x15\",\"domain\":[0.0,0.12]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CRIM\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"ZN\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"INDUS\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CHAS\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.78,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"NOX\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.78,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"RM\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.78,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"AGE\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.56,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"DIS\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.56,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"RAD\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.56,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"TAX\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.33999999999999997,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"PTRATIO\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.33999999999999997,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"B\",\"x\":0.8555555555555556,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.33999999999999997,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LSTAT\",\"x\":0.14444444444444446,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.12,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MEDV\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.12,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"height\":1000,\"width\":550,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b518d61d-af4e-41e0-9a4c-6ac801bb00ea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "total_items = len(df.columns)\n",
        "items_per_row = 3\n",
        "total_rows = math.ceil(total_items / items_per_row)\n",
        "\n",
        "fig = make_subplots(rows=total_rows, cols=items_per_row, subplot_titles=df.columns)\n",
        "\n",
        "cur_row = 1\n",
        "cur_col = 1\n",
        "\n",
        "for index, column in enumerate(df.columns):\n",
        "    fig.add_trace(go.Scattergl(x=df[column], \n",
        "                            y=df['MEDV'], \n",
        "                            mode=\"markers\", \n",
        "                            marker=dict(size=3)), \n",
        "                  row=cur_row, \n",
        "                  col=cur_col)\n",
        "    \n",
        "    intercept = np.poly1d(np.polyfit(df[column], df['MEDV'], 1))(np.unique(df[column]))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(x=np.unique(df[column]), \n",
        "                             y=intercept, \n",
        "                             line=dict(color='red', width=1)), \n",
        "                  row=cur_row, \n",
        "                  col=cur_col)\n",
        "    \n",
        "    if cur_col % items_per_row == 0:\n",
        "        cur_col = 1\n",
        "        cur_row = cur_row + 1\n",
        "    else:\n",
        "        cur_col = cur_col + 1\n",
        "    \n",
        "\n",
        "fig.update_layout(height=1000, width=550, showlegend=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKfZmrMry8Ip"
      },
      "source": [
        "\n",
        "From this initial data exploration, we can have two major conclusions:\n",
        "\n",
        "- There is a strong linear correlation between the RM (average number of rooms per dwelling) and LSTAT (% lower status of the population) with the target variable, being the RM a positive and the LSTAT a negative correlation.\n",
        "- There are some records containing outliers, which we could preprocess in order to input our model with more normalized data.\n",
        "\n",
        "### Data preprocessing\n",
        "\n",
        "Before we proceed into any data preprocessing, it's important to split our data into training and test sets. We should not apply any kind of preprocessing into our data without taking into account that we should not leak information from our test set. For this step, we can use the *train_test_split* method from scikit-learn. In this case, we will use a split of 70% of the data for training and 30% for testing. We also set a random_state seed, in order to allow reprocibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "E0bVtzGQy8Iq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.loc[:, df.columns != 'MEDV']\n",
        "y = df.loc[:, df.columns == 'MEDV']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP-AHuPZy8Ir"
      },
      "source": [
        "In order to provide a standardized input to our neural network, we need the perform the normalization of our dataset. This can be seen as an step to reduce the differences in scale that may arise from the existent features. We perform this normalization by subtracting the mean from our data and dividing it by the standard deviation. **One more time,  this normalization should only be performed by using the mean and standard deviation from the training set, in order to avoid any information leak from the test set.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "V0YFqccQy8Is"
      },
      "outputs": [],
      "source": [
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvSgRMS-y8It"
      },
      "source": [
        "\n",
        "### Build our model\n",
        "\n",
        "Due to the small amount of presented data in this dataset, we must be careful to not create an overly complex model, which could lead to overfitting our data. For this, we are going to adopt an architecture based on two Dense layers, the first with 128 and the second with 64 neurons, both using a ReLU activation function. A dense layer with a linear activation will be used as output layer.\n",
        "\n",
        "In order to allow us to know if our model is properly learning, we will use a mean squared error loss function and to report the performance of it we will adopt the mean average error metric.\n",
        "\n",
        "By using the summary method from Keras, we can see that we have a total of 5,121 parameters, which is acceptable for us.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ko12kBidy8It",
        "outputId": "bb91a726-4b9a-4cb0-e2a2-e04b46101d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3iS-aA3y8Iu"
      },
      "source": [
        "\n",
        "### Train our model\n",
        "\n",
        "This step is pretty straightforward: fit our model with both our features and their labels, for a total amount of 100 epochs, separating 5% of the samples (18 records) as validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "id": "XtwnpjMMy8Iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db81a14-c891-4e8a-c96b-1609a4adabaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 44ms/step - loss: 630.7045 - mae: 23.6856 - val_loss: 549.3899 - val_mae: 22.1075\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 591.0640 - mae: 22.8524 - val_loss: 511.7638 - val_mae: 21.2801\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 547.6979 - mae: 21.9243 - val_loss: 471.1449 - val_mae: 20.3432\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 501.6457 - mae: 20.8715 - val_loss: 425.5368 - val_mae: 19.2382\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 446.6737 - mae: 19.5762 - val_loss: 374.4377 - val_mae: 17.9160\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 388.1941 - mae: 18.0461 - val_loss: 316.8883 - val_mae: 16.3127\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 324.8260 - mae: 16.3144 - val_loss: 257.4010 - val_mae: 14.4518\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 260.8378 - mae: 14.3211 - val_loss: 198.7682 - val_mae: 12.3431\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 198.9293 - mae: 12.1857 - val_loss: 144.6452 - val_mae: 10.4844\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 145.3049 - mae: 9.9839 - val_loss: 100.4579 - val_mae: 8.8485\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 103.7225 - mae: 8.1764 - val_loss: 70.1792 - val_mae: 7.5290\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 77.8775 - mae: 6.9331 - val_loss: 51.5891 - val_mae: 6.2167\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 61.1549 - mae: 6.0114 - val_loss: 40.4842 - val_mae: 5.2121\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 50.9072 - mae: 5.4294 - val_loss: 32.4756 - val_mae: 4.7201\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 42.3714 - mae: 4.8832 - val_loss: 24.8743 - val_mae: 4.1298\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 33.7875 - mae: 4.3081 - val_loss: 19.8827 - val_mae: 3.7217\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 27.7577 - mae: 3.9004 - val_loss: 16.8761 - val_mae: 3.4944\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 23.9900 - mae: 3.6010 - val_loss: 15.2057 - val_mae: 3.2989\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 21.7201 - mae: 3.3957 - val_loss: 14.3712 - val_mae: 3.1354\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 20.0957 - mae: 3.2698 - val_loss: 13.8252 - val_mae: 2.9623\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 18.6857 - mae: 3.1579 - val_loss: 13.5599 - val_mae: 2.8714\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 17.5893 - mae: 3.0898 - val_loss: 13.4981 - val_mae: 2.7708\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 16.6736 - mae: 3.0213 - val_loss: 13.5269 - val_mae: 2.6928\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 16.0237 - mae: 2.9794 - val_loss: 13.4735 - val_mae: 2.6853\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 15.2758 - mae: 2.9237 - val_loss: 13.1613 - val_mae: 2.6965\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 14.6567 - mae: 2.8725 - val_loss: 12.7125 - val_mae: 2.6787\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 14.0895 - mae: 2.8161 - val_loss: 12.1563 - val_mae: 2.6648\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.5563 - mae: 2.7689 - val_loss: 11.5348 - val_mae: 2.6468\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.0936 - mae: 2.7304 - val_loss: 11.2484 - val_mae: 2.6059\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.6589 - mae: 2.6915 - val_loss: 11.0368 - val_mae: 2.6477\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 12.2533 - mae: 2.6526 - val_loss: 10.8898 - val_mae: 2.6464\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 11.8765 - mae: 2.6213 - val_loss: 10.7028 - val_mae: 2.6357\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.4842 - mae: 2.5812 - val_loss: 10.2711 - val_mae: 2.6249\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.1713 - mae: 2.5440 - val_loss: 10.0588 - val_mae: 2.6322\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 10.8828 - mae: 2.5149 - val_loss: 10.0244 - val_mae: 2.5992\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 10.5670 - mae: 2.4935 - val_loss: 9.9117 - val_mae: 2.5933\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 10.3256 - mae: 2.4638 - val_loss: 9.6116 - val_mae: 2.6069\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0777 - mae: 2.4131 - val_loss: 9.4652 - val_mae: 2.7033\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.8939 - mae: 2.3915 - val_loss: 9.8436 - val_mae: 2.7735\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.6516 - mae: 2.3685 - val_loss: 10.0647 - val_mae: 2.7816\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.3725 - mae: 2.3439 - val_loss: 9.8494 - val_mae: 2.7309\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.2067 - mae: 2.3335 - val_loss: 9.6564 - val_mae: 2.6638\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.9508 - mae: 2.3134 - val_loss: 9.4226 - val_mae: 2.6529\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.7508 - mae: 2.2764 - val_loss: 9.0203 - val_mae: 2.6369\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.6495 - mae: 2.2441 - val_loss: 8.8147 - val_mae: 2.6371\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.4642 - mae: 2.2145 - val_loss: 8.7172 - val_mae: 2.5757\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.2509 - mae: 2.2002 - val_loss: 8.6144 - val_mae: 2.5092\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.2144 - mae: 2.1999 - val_loss: 8.5989 - val_mae: 2.4869\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.0615 - mae: 2.1836 - val_loss: 8.5109 - val_mae: 2.4936\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.9354 - mae: 2.1596 - val_loss: 8.3416 - val_mae: 2.4998\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.7726 - mae: 2.1344 - val_loss: 8.4610 - val_mae: 2.5182\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.6854 - mae: 2.1290 - val_loss: 8.3766 - val_mae: 2.5141\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.5763 - mae: 2.1180 - val_loss: 8.2481 - val_mae: 2.5024\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.4852 - mae: 2.1018 - val_loss: 7.9921 - val_mae: 2.4592\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.4085 - mae: 2.0805 - val_loss: 7.7574 - val_mae: 2.4489\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.1911 - mae: 2.0291 - val_loss: 7.4534 - val_mae: 2.4096\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.1319 - mae: 2.0180 - val_loss: 7.2733 - val_mae: 2.4066\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.0180 - mae: 2.0055 - val_loss: 7.3184 - val_mae: 2.4460\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.9577 - mae: 1.9848 - val_loss: 7.5375 - val_mae: 2.5235\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.8225 - mae: 1.9546 - val_loss: 7.4752 - val_mae: 2.5141\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.7660 - mae: 1.9485 - val_loss: 7.3658 - val_mae: 2.4768\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.6549 - mae: 1.9346 - val_loss: 7.4102 - val_mae: 2.4716\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.5329 - mae: 1.9095 - val_loss: 7.2678 - val_mae: 2.4355\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.4488 - mae: 1.8824 - val_loss: 7.0543 - val_mae: 2.3586\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.3544 - mae: 1.8675 - val_loss: 6.8910 - val_mae: 2.3146\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.3205 - mae: 1.8645 - val_loss: 6.9196 - val_mae: 2.2868\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2196 - mae: 1.8425 - val_loss: 6.9775 - val_mae: 2.3001\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.1243 - mae: 1.8257 - val_loss: 6.9858 - val_mae: 2.3186\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0528 - mae: 1.8208 - val_loss: 7.1074 - val_mae: 2.3056\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.0619 - mae: 1.8364 - val_loss: 6.9305 - val_mae: 2.2574\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.9894 - mae: 1.8142 - val_loss: 6.8277 - val_mae: 2.2597\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.8657 - mae: 1.7839 - val_loss: 6.8158 - val_mae: 2.3001\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.9210 - mae: 1.7711 - val_loss: 6.9295 - val_mae: 2.3731\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.7819 - mae: 1.7526 - val_loss: 6.7320 - val_mae: 2.3358\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.6342 - mae: 1.7377 - val_loss: 6.3165 - val_mae: 2.2254\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.6788 - mae: 1.7447 - val_loss: 6.1427 - val_mae: 2.1451\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.6309 - mae: 1.7501 - val_loss: 6.1760 - val_mae: 2.1703\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.6059 - mae: 1.7498 - val_loss: 6.3120 - val_mae: 2.2307\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.4506 - mae: 1.7279 - val_loss: 6.3493 - val_mae: 2.2869\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3976 - mae: 1.7090 - val_loss: 6.3212 - val_mae: 2.3160\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3074 - mae: 1.6812 - val_loss: 6.1308 - val_mae: 2.2757\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3039 - mae: 1.6717 - val_loss: 6.0416 - val_mae: 2.2422\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.2300 - mae: 1.6541 - val_loss: 5.9118 - val_mae: 2.2283\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.1852 - mae: 1.6392 - val_loss: 5.9799 - val_mae: 2.2396\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.1477 - mae: 1.6359 - val_loss: 6.1454 - val_mae: 2.2707\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.1621 - mae: 1.6531 - val_loss: 6.1654 - val_mae: 2.2489\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.1405 - mae: 1.6571 - val_loss: 5.8568 - val_mae: 2.1621\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.0717 - mae: 1.6347 - val_loss: 5.7239 - val_mae: 2.1091\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9981 - mae: 1.6154 - val_loss: 5.6931 - val_mae: 2.1242\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.9276 - mae: 1.5895 - val_loss: 5.6549 - val_mae: 2.1497\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9104 - mae: 1.5849 - val_loss: 5.4372 - val_mae: 2.1115\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8112 - mae: 1.5649 - val_loss: 5.4277 - val_mae: 2.1326\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.8676 - mae: 1.5604 - val_loss: 5.7881 - val_mae: 2.2067\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.8267 - mae: 1.5579 - val_loss: 5.6705 - val_mae: 2.1878\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.7088 - mae: 1.5410 - val_loss: 5.4935 - val_mae: 2.1357\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.6561 - mae: 1.5288 - val_loss: 5.2351 - val_mae: 2.0658\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6157 - mae: 1.5250 - val_loss: 5.1515 - val_mae: 2.0348\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5615 - mae: 1.5135 - val_loss: 5.3003 - val_mae: 2.0765\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5698 - mae: 1.4993 - val_loss: 5.5106 - val_mae: 2.1303\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.5067 - mae: 1.4860 - val_loss: 5.3771 - val_mae: 2.1044\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Architechture and Weights:"
      ],
      "metadata": {
        "id": "8IGwSQ93q7PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "#json_model\n",
        "#save the model architecture to JSON file\n",
        "with open('client1_nn.json', 'w') as json_file:\n",
        "    json_file.write(json_model)"
      ],
      "metadata": {
        "id": "2i3lSOD8q-bc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('client1_nn.h5')"
      ],
      "metadata": {
        "id": "b2xL1ItR5aJf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "weight_layer_1=model.layers[0].get_weights()[0]\n",
        "bias_layer_1=model.layers[0].get_weights()[1]\n",
        "\n",
        "weight_layer_2=model.layers[1].get_weights()[0]\n",
        "bias_layer_2=model.layers[1].get_weights()[1]\n",
        "\n",
        "weight_layer_3=model.layers[2].get_weights()[0]\n",
        "bias_layer_3=model.layers[2].get_weights()[1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BpEo0OqDDrbM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.name)\n",
        "  print(\"Weights\")\n",
        "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
        "  print(\"Bias\")\n",
        "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
        "  count+=1\n"
      ],
      "metadata": {
        "id": "KYnAgRi-2UG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Weights and biases of the layers before training the model: \\n\")\n",
        "count=0\n",
        "ls=[]\n",
        "for layer in model.layers:\n",
        "  print(layer.name)\n",
        "  print(\"Weights\")\n",
        "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
        "  print(\"Bias\")\n",
        "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
        "  count+=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HHuuXtO-Tv5",
        "outputId": "1f4432d8-16c8-40b2-eaee-44ae67dfc8b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and biases of the layers before training the model: \n",
            "\n",
            "dense_1\n",
            "Weights\n",
            "Shape:  (13, 128) \n",
            " [[-0.10810528 -0.04256306 -0.32970807 ... -0.2242326   0.06780985\n",
            "  -0.2210991 ]\n",
            " [ 0.17021643  0.1209093  -0.13986905 ... -0.30583155  0.10146755\n",
            "  -0.24131566]\n",
            " [ 0.05480978  0.10779033 -0.1265292  ...  0.03445881 -0.25715473\n",
            "  -0.16110232]\n",
            " ...\n",
            " [ 0.14985943  0.07588912  0.05417326 ...  0.19791451 -0.04375117\n",
            "  -0.02651396]\n",
            " [ 0.18616603  0.18403901  0.07211368 ... -0.01363186  0.03238907\n",
            "   0.04770255]\n",
            " [ 0.14969552 -0.14312036  0.12826504 ... -0.1398269   0.05949314\n",
            "   0.00341396]]\n",
            "Bias\n",
            "Shape:  (128,) \n",
            " [ 0.10427078  0.03306334  0.14168441  0.09490094  0.10245746  0.11478715\n",
            "  0.11075933  0.09493779  0.13837825  0.07687748  0.08022442  0.0880478\n",
            "  0.02440797  0.10468347  0.09549816  0.14481948  0.03743838  0.07914388\n",
            "  0.10685676  0.0871152   0.02271743  0.08798667  0.10973434  0.08685806\n",
            "  0.03996862  0.10051718  0.12090113  0.10558893  0.11112651  0.09427129\n",
            "  0.08655947  0.12190478  0.10848884  0.06113871  0.03267827  0.09887938\n",
            "  0.04776769  0.1403934   0.11742072  0.10001839  0.07853795  0.10393149\n",
            "  0.09861113  0.11539754  0.12285327  0.05375064  0.06096703  0.09417839\n",
            "  0.07449783  0.13707584  0.14907317  0.1243889   0.05628336  0.15198374\n",
            "  0.12130225  0.05722746  0.15586898  0.09267946  0.11350559  0.10692099\n",
            "  0.11670839  0.07892284  0.10548263  0.15206608  0.10979012  0.09085525\n",
            " -0.0331952   0.11232044  0.09889416  0.12663384  0.09404814  0.11826544\n",
            "  0.14218445  0.10391643 -0.00176445  0.08807042  0.07242051  0.09446555\n",
            "  0.10958984  0.05402201  0.00148055  0.11539865  0.10378589 -0.04876468\n",
            "  0.07849318  0.10463038  0.13265643  0.11951381  0.1065964   0.10300042\n",
            "  0.1342493   0.11426856  0.05493061  0.12162352  0.13179961  0.09618768\n",
            "  0.10215832  0.11517869  0.10492977  0.09954616  0.10686991  0.10031652\n",
            "  0.03156523  0.12406272  0.11311323  0.07322288  0.11226534  0.0776248\n",
            "  0.09141544  0.10990999  0.09039501 -0.02533666  0.11564381  0.13057655\n",
            "  0.09620581  0.13747291  0.08385076  0.08696088  0.09745044  0.10493334\n",
            "  0.10227887  0.14831835  0.13155884  0.12930764  0.0901584   0.13438925\n",
            "  0.11804026  0.1654534 ] \n",
            "\n",
            "dense_2\n",
            "Weights\n",
            "Shape:  (128, 64) \n",
            " [[-0.13956334  0.14160955  0.18279877 ... -0.05122372  0.13736993\n",
            "   0.20674317]\n",
            " [-0.03918414 -0.07576089  0.00877502 ...  0.12854816 -0.12417206\n",
            "  -0.0562002 ]\n",
            " [-0.02837341  0.20174631 -0.06520871 ...  0.14223322 -0.16068503\n",
            "   0.10433493]\n",
            " ...\n",
            " [-0.1089768   0.14017618  0.10153068 ...  0.27052057 -0.03812202\n",
            "   0.25172797]\n",
            " [ 0.04544482 -0.08344211  0.08939686 ... -0.0505291   0.03899256\n",
            "  -0.01419986]\n",
            " [ 0.04231645  0.24907987  0.0916652  ...  0.17298482 -0.11124378\n",
            "   0.07558767]]\n",
            "Bias\n",
            "Shape:  (64,) \n",
            " [-0.03649895  0.08817654  0.08741402  0.08549988 -0.0146447   0.1110634\n",
            "  0.07617182  0.08927598  0.09302921 -0.01199144 -0.01369337 -0.02296632\n",
            "  0.08086358 -0.02723847  0.08448307  0.09277755 -0.02729972  0.08245386\n",
            " -0.0204155   0.09166934  0.0920928   0.07913712  0.08973414  0.11215372\n",
            "  0.09424713 -0.02078302 -0.0063511  -0.02782245 -0.01907128  0.08361951\n",
            "  0.08637442  0.11656185 -0.02083539  0.08074937  0.08737808  0.0925649\n",
            "  0.1073617  -0.02118985 -0.01937212 -0.02747952 -0.01611102  0.09297975\n",
            " -0.02997751 -0.02600955  0.09594449  0.0801449   0.08262651  0.09266251\n",
            " -0.01714273  0.08030707 -0.02731959 -0.03047496 -0.02833191 -0.02070704\n",
            " -0.02432207  0.0831406   0.10068785 -0.02117631  0.0883676  -0.01104009\n",
            " -0.02859076  0.11016067 -0.01606915  0.07671937] \n",
            "\n",
            "dense_output\n",
            "Weights\n",
            "Shape:  (64, 1) \n",
            " [[-0.04262466]\n",
            " [ 0.23427604]\n",
            " [ 0.1756306 ]\n",
            " [ 0.37602937]\n",
            " [-0.04631475]\n",
            " [ 0.11736532]\n",
            " [ 0.37677303]\n",
            " [ 0.1458813 ]\n",
            " [ 0.11816783]\n",
            " [-0.2561081 ]\n",
            " [-0.09561356]\n",
            " [-0.13013884]\n",
            " [ 0.2540423 ]\n",
            " [-0.07675301]\n",
            " [ 0.19949429]\n",
            " [ 0.16988705]\n",
            " [-0.07260529]\n",
            " [ 0.3333482 ]\n",
            " [-0.00973738]\n",
            " [ 0.21622247]\n",
            " [ 0.14946765]\n",
            " [ 0.3455994 ]\n",
            " [ 0.26999262]\n",
            " [ 0.11181876]\n",
            " [ 0.27614713]\n",
            " [-0.27628732]\n",
            " [-0.25351346]\n",
            " [-0.20161642]\n",
            " [-0.17460187]\n",
            " [ 0.23434271]\n",
            " [ 0.3422219 ]\n",
            " [ 0.11583045]\n",
            " [-0.41695845]\n",
            " [ 0.2944803 ]\n",
            " [ 0.35368901]\n",
            " [ 0.24061434]\n",
            " [ 0.10662565]\n",
            " [-0.02288621]\n",
            " [-0.0692399 ]\n",
            " [-0.03925385]\n",
            " [-0.23126453]\n",
            " [ 0.19158192]\n",
            " [-0.25915942]\n",
            " [-0.19266805]\n",
            " [ 0.20472412]\n",
            " [ 0.25883615]\n",
            " [ 0.379728  ]\n",
            " [ 0.3816884 ]\n",
            " [-0.12137092]\n",
            " [ 0.35884237]\n",
            " [-0.25054947]\n",
            " [-0.07705913]\n",
            " [-0.01369059]\n",
            " [-0.2323221 ]\n",
            " [-0.11632285]\n",
            " [ 0.29106405]\n",
            " [ 0.11821474]\n",
            " [-0.09514039]\n",
            " [ 0.3055819 ]\n",
            " [-0.03287783]\n",
            " [-0.03174323]\n",
            " [ 0.27842063]\n",
            " [-0.1709866 ]\n",
            " [ 0.3787556 ]]\n",
            "Bias\n",
            "Shape:  (1,) \n",
            " [0.07210866] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w,bias=model.layers[0].get_weights()\n",
        "w=np.asarray(w)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4wiI8T8jBpq",
        "outputId": "6a7c72e7-0c0d-4f54-fa03-3f7eada3f781"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10810528, -0.04256306, -0.32970807, ..., -0.2242326 ,\n",
              "         0.06780985, -0.2210991 ],\n",
              "       [ 0.17021643,  0.1209093 , -0.13986905, ..., -0.30583155,\n",
              "         0.10146755, -0.24131566],\n",
              "       [ 0.05480978,  0.10779033, -0.1265292 , ...,  0.03445881,\n",
              "        -0.25715473, -0.16110232],\n",
              "       ...,\n",
              "       [ 0.14985943,  0.07588912,  0.05417326, ...,  0.19791451,\n",
              "        -0.04375117, -0.02651396],\n",
              "       [ 0.18616603,  0.18403901,  0.07211368, ..., -0.01363186,\n",
              "         0.03238907,  0.04770255],\n",
              "       [ 0.14969552, -0.14312036,  0.12826504, ..., -0.1398269 ,\n",
              "         0.05949314,  0.00341396]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9dZIEsUy8Iv"
      },
      "source": [
        "By plotting both loss and mean average error, we can see that our model was capable of learning patterns in our data without overfitting taking place (as shown by the validation set curves):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-Ff9Hxfy8Iw",
        "outputId": "3ef15d90-d099-46d4-a32c-4e2c77525339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"95ac93d7-2747-4000-8014-19c7ec9e306d\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"95ac93d7-2747-4000-8014-19c7ec9e306d\")) {                    Plotly.newPlot(                        \"95ac93d7-2747-4000-8014-19c7ec9e306d\",                        [{\"name\":\"Train\",\"y\":[648.996826171875,615.795654296875,579.656982421875,539.0093994140625,491.82159423828125,435.6201171875,372.82379150390625,305.51568603515625,238.18515014648438,174.4456329345703,119.0788345336914,81.30449676513672,60.32126998901367,48.221046447753906,40.7357177734375,34.83012008666992,29.517648696899414,25.473403930664062,23.138673782348633,21.04012107849121,19.583345413208008,18.414194107055664,17.379182815551758,16.443965911865234,15.528244972229004,14.697897911071777,14.019247055053711,13.434504508972168,12.94284725189209,12.429831504821777,12.050955772399902,11.625016212463379,11.273510932922363,10.9161958694458,10.590450286865234,10.292428970336914,10.093964576721191,9.774264335632324,9.562715530395508,9.333176612854004,9.120565414428711,8.925877571105957,8.712967872619629,8.530139923095703,8.35819149017334,8.237626075744629,8.049257278442383,7.907726764678955,7.798222064971924,7.670932292938232,7.539412498474121,7.468480110168457,7.414276599884033,7.297812461853027,7.230076789855957,7.129603385925293,7.012950420379639,6.867302894592285,6.811744689941406,6.739022731781006,6.707298755645752,6.603092193603516,6.526758193969727,6.406796932220459,6.370287895202637,6.293358325958252,6.1706085205078125,6.130104064941406,6.0440354347229,5.951752662658691,5.887397289276123,5.867224216461182,5.773481369018555,5.794803619384766,5.78354549407959,5.667294979095459,5.579127311706543,5.589639186859131,5.606902122497559,5.482039928436279,5.413672924041748,5.387630939483643,5.303700923919678,5.21659517288208,5.167174816131592,5.1360697746276855,5.0491766929626465,5.009806156158447,4.985890865325928,4.965475559234619,4.920611381530762,4.886497974395752,4.829522132873535,4.794402122497559,4.834992408752441,4.823873519897461,4.73836088180542,4.637083530426025,4.6373677253723145,4.604794502258301],\"type\":\"scattergl\"},{\"name\":\"Valid\",\"y\":[575.9279174804688,542.992919921875,507.5517578125,466.71197509765625,419.8271484375,366.2972717285156,307.4355163574219,246.3037872314453,186.43988037109375,133.11289978027344,91.23468780517578,62.76130676269531,45.606746673583984,36.00509262084961,29.36766815185547,24.06273651123047,20.377843856811523,17.7877197265625,15.901430130004883,14.576315879821777,13.385709762573242,11.964423179626465,11.177624702453613,10.96993350982666,10.88779067993164,10.885941505432129,10.9550142288208,10.960680961608887,10.860579490661621,10.818473815917969,10.744300842285156,10.867786407470703,10.838949203491211,10.754096031188965,10.73477554321289,10.674948692321777,10.592768669128418,10.411751747131348,10.14302921295166,10.025569915771484,9.922505378723145,9.94996166229248,9.821276664733887,9.865259170532227,10.036641120910645,10.154135704040527,10.388588905334473,10.535083770751953,10.458266258239746,10.217629432678223,10.00316047668457,9.852392196655273,9.824840545654297,9.998909950256348,9.911126136779785,9.896035194396973,9.606937408447266,9.553606986999512,9.904313087463379,9.74129867553711,9.63388729095459,9.773601531982422,9.89529037475586,9.963982582092285,9.999103546142578,9.987104415893555,9.963109970092773,9.716531753540039,9.295013427734375,8.986367225646973,8.823180198669434,8.513094902038574,8.706295013427734,8.84836196899414,8.711287498474121,8.593364715576172,8.227346420288086,8.161561965942383,8.221485137939453,8.559253692626953,9.060091972351074,9.194989204406738,8.940613746643066,8.622560501098633,8.442601203918457,8.404107093811035,8.352104187011719,8.235184669494629,8.24138069152832,7.970762252807617,7.783650875091553,7.815285682678223,7.620936870574951,7.225069522857666,7.002073287963867,6.994670867919922,7.263374328613281,7.550742149353027,7.650561809539795,7.475696086883545],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"height\":500,\"width\":700,\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('95ac93d7-2747-4000-8014-19c7ec9e306d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
        "                    name='Train'))\n",
        "\n",
        "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "\n",
        "\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elriLxroy8Ix"
      },
      "source": [
        "### Evaluate our model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0l2w9Bbwy8Ix",
        "outputId": "9a710a6b-a97a-4484-fb9a-84bc3c76f005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 109ms/step - loss: 8.4515 - mae: 2.2009\n",
            "Mean squared error on test data:  8.451534271240234\n",
            "Mean absolute error on test data:  2.2009472846984863\n"
          ]
        }
      ],
      "source": [
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error on test data: ', mse_nn)\n",
        "print('Mean absolute error on test data: ', mae_nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retraining with updated model co-efficients:"
      ],
      "metadata": {
        "id": "7TEoxkTqNWyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Previous Architecture of Model:\n"
      ],
      "metadata": {
        "id": "sCJSkiWJUcwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Model 1 weights:"
      ],
      "metadata": {
        "id": "cwOPaffBsV0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "id": "fhifngAFrccz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "# Creating a new model from the saved JSON file\n",
        "# reda the model from the JSOn file\n",
        "with open('client1_nn.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "#json_savedModel\n",
        "#load the model architecture \n",
        "model_1 = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-oZlF63rSvf",
        "outputId": "394150bf-89af-42e9-b895-49bdca1d91d3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the List of numpy arrays of Updated Weights"
      ],
      "metadata": {
        "id": "9xutz2LTVMCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"updated_layer_1.json\", \"rb\") as fp1:\n",
        "  ls1=pickle.load(fp1)\n",
        "with open(\"updated_layer_2.json\", \"rb\") as fp2:\n",
        "  ls2=pickle.load(fp2)\n",
        "with open(\"updated_layer_3.json\", \"rb\") as fp3:\n",
        "  ls3=pickle.load(fp3)"
      ],
      "metadata": {
        "id": "SBv9hbLpVR_d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weight , Bias of layer 1\")\n",
        "np.shape(ls1[0]),np.shape(ls1[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ4s4FKOWUTl",
        "outputId": "189ed8a3-3121-4085-c813-94bd18d68b87"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight , Bias of layer 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13, 128), (128,))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weight , Bias of layer 2\")\n",
        "np.shape(ls2[0]),np.shape(ls2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512b2864-8ffd-41b8-a909-7b2735db50f4",
        "id": "QWK6QkIHXrao"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight , Bias of layer 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((128, 64), (64,))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weight , Bias of layer 3\")\n",
        "np.shape(ls3[0]),np.shape(ls3[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a834e981-2699-4830-e2e5-04577568b38e",
        "id": "03lteXzMXzke"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight , Bias of layer 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 1), (1,))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting the updated weights in model"
      ],
      "metadata": {
        "id": "-ALL7DqFVmqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "i7sfwBDTXFo7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Layer 1 Weight {np.shape(ls2[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsZ3jTh7W1UP",
        "outputId": "f764aab6-51ca-4eb8-a874-02215bbe1604"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Layer 1 Weight (128, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.layers[0].set_weights(ls1)"
      ],
      "metadata": {
        "id": "__TGprksVqEM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.layers[1].set_weights(ls2)"
      ],
      "metadata": {
        "id": "2G_JUO6lV_T2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.layers[2].set_weights(ls3)"
      ],
      "metadata": {
        "id": "SKKGIRsIWA3h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Round 1 of Averaging: Weights and biases of the layers before training : \\n\")\n",
        "count=0\n",
        "ls=[]\n",
        "for layer in model_1.layers:\n",
        "  print(layer.name)\n",
        "  print(\"Weights\")\n",
        "  print(\"Shape: \",layer.get_weights()[0].shape,'\\n',layer.get_weights()[0])\n",
        "  print(\"Bias\")\n",
        "  print(\"Shape: \",layer.get_weights()[1].shape,'\\n',layer.get_weights()[1],'\\n')\n",
        "  count+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atrki40IYTl7",
        "outputId": "b3606cfc-0c84-4877-e61f-81d8e62c1744"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1 of Averaging: Weights and biases of the layers before training : \n",
            "\n",
            "dense_1\n",
            "Weights\n",
            "Shape:  (13, 128) \n",
            " [[ 6.20943308e-02 -1.78483278e-01 -1.02627665e-01 ...  2.57962830e-02\n",
            "  -7.57881925e-02 -1.13780670e-01]\n",
            " [-3.46610397e-02  6.03686534e-02 -1.22795708e-01 ...  1.10384226e-02\n",
            "   1.25830933e-01 -3.39010730e-04]\n",
            " [ 9.89168361e-02 -1.88106611e-01  1.48603730e-02 ...  1.31532550e-04\n",
            "  -2.36775130e-02 -1.26437113e-01]\n",
            " ...\n",
            " [ 3.86220217e-03  2.81191356e-02 -2.66750515e-01 ... -1.85343191e-01\n",
            "   7.72679448e-02  9.53996703e-02]\n",
            " [-1.08798683e-01  1.21338507e-02  2.08816499e-01 ...  1.49667889e-01\n",
            "   2.09382176e-02 -5.49083985e-02]\n",
            " [-5.45909479e-02  3.19619589e-02 -1.03366733e-01 ... -3.93435098e-02\n",
            "   4.24711704e-02  1.92250177e-01]]\n",
            "Bias\n",
            "Shape:  (128,) \n",
            " [0.05488506 0.08146667 0.12298182 0.12015612 0.07622987 0.10471848\n",
            " 0.09643918 0.12511289 0.06834874 0.12589926 0.08692739 0.10243049\n",
            " 0.14626242 0.07084406 0.07910706 0.09141494 0.02152244 0.08845909\n",
            " 0.10820374 0.09974018 0.09458604 0.08293125 0.04409681 0.10082066\n",
            " 0.0899906  0.0298817  0.05696315 0.08652622 0.10765913 0.06557263\n",
            " 0.03379823 0.06937273 0.0804068  0.04486    0.11478603 0.08264057\n",
            " 0.12482192 0.07151024 0.09766088 0.12656356 0.0909193  0.02683542\n",
            " 0.05745598 0.0556036  0.02857184 0.11304972 0.09756155 0.00250372\n",
            " 0.05007005 0.06860472 0.10209255 0.11819652 0.08613481 0.09697901\n",
            " 0.06838264 0.0851654  0.08873389 0.03896099 0.08308925 0.07575803\n",
            " 0.08712319 0.09959571 0.06916652 0.08385688 0.01394856 0.0742141\n",
            " 0.07989409 0.05941503 0.11154699 0.02862579 0.06491943 0.09497873\n",
            " 0.09470099 0.10548423 0.10881338 0.06730237 0.01203393 0.07209939\n",
            " 0.06364228 0.06262993 0.07443806 0.10430367 0.09321801 0.07976795\n",
            " 0.06451718 0.10081226 0.05754524 0.1077483  0.07654189 0.08314402\n",
            " 0.10836324 0.08725098 0.06661044 0.11729564 0.08384749 0.09348808\n",
            " 0.1161641  0.10493322 0.11422102 0.1046612  0.07426017 0.08254359\n",
            " 0.09228794 0.08150527 0.10362054 0.05724456 0.05356495 0.12544268\n",
            " 0.08270144 0.05025401 0.06972673 0.10070914 0.07324904 0.09562333\n",
            " 0.11934252 0.09927859 0.11728705 0.0889069  0.05362418 0.11157086\n",
            " 0.02582438 0.07140666 0.10474358 0.00194842 0.079669   0.07114045\n",
            " 0.0517514  0.10676389] \n",
            "\n",
            "dense_2\n",
            "Weights\n",
            "Shape:  (128, 64) \n",
            " [[-9.59096104e-03  9.65702906e-02  7.53114298e-02 ...  1.46067396e-01\n",
            "  -1.64632946e-01  1.03378296e-03]\n",
            " [ 3.68881524e-02  6.68729544e-02 -3.87455076e-02 ...  5.40563613e-02\n",
            "  -5.16189188e-02  1.27109215e-02]\n",
            " [-4.36170772e-03  3.15779671e-02  3.96478958e-02 ... -9.61267669e-03\n",
            "  -1.74768463e-01 -6.44996837e-02]\n",
            " ...\n",
            " [-5.73900342e-02  1.42888412e-01  1.42060935e-01 ...  9.85495523e-02\n",
            "  -7.15386122e-03 -2.44511366e-02]\n",
            " [ 4.21497747e-02  5.65143786e-02 -4.81832251e-02 ...  1.74752437e-04\n",
            "   1.89906582e-02  7.80608878e-02]\n",
            " [ 1.32817745e-01  1.52524620e-01  1.26998350e-01 ...  1.27003081e-02\n",
            "  -1.14535801e-01  9.88047048e-02]]\n",
            "Bias\n",
            "Shape:  (64,) \n",
            " [ 0.02499611  0.07747251  0.07650888  0.07893161  0.08715837  0.02603123\n",
            "  0.02742126 -0.02530267  0.02704149  0.07674945  0.02775105  0.03845951\n",
            " -0.02970699 -0.01904802  0.04542287  0.08252427 -0.01747726  0.08645903\n",
            "  0.02731796  0.03020233  0.06481889 -0.01934893  0.02967098  0.04305863\n",
            " -0.02057241  0.07694791  0.07996722  0.03267688  0.07522762  0.08305776\n",
            "  0.03388041 -0.01930526  0.07205264  0.04988256  0.02506694  0.02762938\n",
            " -0.01935885 -0.02270157  0.02293257  0.03780325  0.0836891   0.02939479\n",
            " -0.02144506 -0.02440236  0.07397728  0.07433306  0.01707529  0.07409546\n",
            "  0.02866891  0.02326954  0.02737358  0.02084525  0.03019805  0.05514701\n",
            "  0.01734678  0.01829937  0.02943791  0.02928307  0.07709245  0.08198857\n",
            " -0.0232637   0.0796245  -0.01226215  0.02732253] \n",
            "\n",
            "dense_output\n",
            "Weights\n",
            "Shape:  (64, 1) \n",
            " [[ 0.03880604]\n",
            " [ 0.32751808]\n",
            " [ 0.28817835]\n",
            " [ 0.18626419]\n",
            " [ 0.17115109]\n",
            " [ 0.07024525]\n",
            " [ 0.07696687]\n",
            " [-0.10772966]\n",
            " [ 0.01900025]\n",
            " [ 0.34783554]\n",
            " [ 0.03622531]\n",
            " [ 0.07188069]\n",
            " [-0.05993756]\n",
            " [-0.13261034]\n",
            " [ 0.00080704]\n",
            " [ 0.21174984]\n",
            " [-0.10954618]\n",
            " [ 0.16688724]\n",
            " [ 0.00876589]\n",
            " [ 0.18479149]\n",
            " [ 0.18162018]\n",
            " [-0.22455862]\n",
            " [ 0.06984206]\n",
            " [ 0.0911494 ]\n",
            " [-0.22984308]\n",
            " [ 0.17814547]\n",
            " [ 0.18291913]\n",
            " [ 0.0942554 ]\n",
            " [ 0.19991103]\n",
            " [ 0.2165256 ]\n",
            " [ 0.01647823]\n",
            " [-0.12882356]\n",
            " [ 0.26120526]\n",
            " [-0.06230256]\n",
            " [ 0.1043275 ]\n",
            " [-0.06563939]\n",
            " [-0.23865092]\n",
            " [-0.07710105]\n",
            " [ 0.05045637]\n",
            " [ 0.04284573]\n",
            " [ 0.21975404]\n",
            " [-0.00941083]\n",
            " [-0.09852858]\n",
            " [-0.11485966]\n",
            " [ 0.278445  ]\n",
            " [ 0.23215592]\n",
            " [-0.3519519 ]\n",
            " [ 0.2429044 ]\n",
            " [ 0.09394576]\n",
            " [-0.01644552]\n",
            " [ 0.03997486]\n",
            " [ 0.0167933 ]\n",
            " [ 0.05885343]\n",
            " [ 0.00798588]\n",
            " [ 0.1074588 ]\n",
            " [ 0.1750572 ]\n",
            " [-0.0037443 ]\n",
            " [ 0.03172714]\n",
            " [ 0.20352218]\n",
            " [ 0.18665648]\n",
            " [-0.21313594]\n",
            " [ 0.33135992]\n",
            " [-0.27932402]\n",
            " [ 0.0952886 ]]\n",
            "Bias\n",
            "Shape:  (1,) \n",
            " [0.06508768] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client1_weight_layer_1=model_1.layers[0].get_weights()[0]\n",
        "client1_bias_layer_1=model_1.layers[0].get_weights()[1]\n",
        "\n",
        "client1_weight_layer_2=model_1.layers[1].get_weights()[0]\n",
        "client1_bias_layer_2=model_1.layers[1].get_weights()[1]\n",
        "\n",
        "client1_weight_layer_3=model_1.layers[2].get_weights()[0]\n",
        "client1_bias_layer_3=model_1.layers[2].get_weights()[1]\n"
      ],
      "metadata": {
        "id": "O4xhZzkEscDk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Retraing with the updated models on same data:\n"
      ],
      "metadata": {
        "id": "TZQLkkCeYqNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MbYzdutZVwc",
        "outputId": "5c5ae366-c663-45ef-805f-39afd033c6ed"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(X_train, y_train, epochs=100, validation_split=0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrewXtX6Y9yx",
        "outputId": "480e8ae1-257d-4650-bcc5-b5b8adf3554f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 39ms/step - loss: 165.7572 - mae: 12.1212 - val_loss: 109.5070 - val_mae: 10.0564\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 111.7245 - mae: 9.8113 - val_loss: 66.3468 - val_mae: 7.8269\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 67.9050 - mae: 7.3507 - val_loss: 34.6746 - val_mae: 5.5098\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 38.3263 - mae: 5.0619 - val_loss: 16.6093 - val_mae: 3.4351\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 23.6002 - mae: 3.7381 - val_loss: 9.2881 - val_mae: 2.4927\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 19.3199 - mae: 3.4044 - val_loss: 7.3930 - val_mae: 2.1244\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.4688 - mae: 3.3281 - val_loss: 6.4958 - val_mae: 1.7114\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 15.2652 - mae: 3.1460 - val_loss: 6.0314 - val_mae: 1.7616\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 13.4352 - mae: 2.9155 - val_loss: 6.3370 - val_mae: 1.9702\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 12.1204 - mae: 2.7238 - val_loss: 6.9180 - val_mae: 2.1538\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.1922 - mae: 2.5662 - val_loss: 6.9457 - val_mae: 2.2457\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 10.2588 - mae: 2.4345 - val_loss: 6.7460 - val_mae: 2.2917\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.6650 - mae: 2.3362 - val_loss: 6.7043 - val_mae: 2.3284\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.2827 - mae: 2.2725 - val_loss: 6.6392 - val_mae: 2.3354\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.9443 - mae: 2.2312 - val_loss: 6.4752 - val_mae: 2.2957\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.5271 - mae: 2.1760 - val_loss: 6.7782 - val_mae: 2.3384\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.0906 - mae: 2.1346 - val_loss: 7.0525 - val_mae: 2.3747\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.7990 - mae: 2.1056 - val_loss: 7.4117 - val_mae: 2.4110\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.4950 - mae: 2.0771 - val_loss: 7.4085 - val_mae: 2.3795\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.2935 - mae: 2.0584 - val_loss: 7.5345 - val_mae: 2.3902\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.1295 - mae: 2.0324 - val_loss: 7.3045 - val_mae: 2.3693\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.9313 - mae: 1.9950 - val_loss: 6.8720 - val_mae: 2.3321\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.7190 - mae: 1.9509 - val_loss: 6.6525 - val_mae: 2.3218\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.5702 - mae: 1.9180 - val_loss: 6.5900 - val_mae: 2.3399\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.5366 - mae: 1.9034 - val_loss: 6.4689 - val_mae: 2.3306\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.3280 - mae: 1.8728 - val_loss: 6.6062 - val_mae: 2.3375\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2215 - mae: 1.8631 - val_loss: 6.8503 - val_mae: 2.3496\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1419 - mae: 1.8598 - val_loss: 6.3496 - val_mae: 2.2537\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9828 - mae: 1.8345 - val_loss: 6.2145 - val_mae: 2.2222\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8714 - mae: 1.8154 - val_loss: 6.0896 - val_mae: 2.2085\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7629 - mae: 1.7949 - val_loss: 5.6709 - val_mae: 2.1292\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7415 - mae: 1.7804 - val_loss: 5.4918 - val_mae: 2.0905\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.6190 - mae: 1.7603 - val_loss: 5.7937 - val_mae: 2.1591\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.5730 - mae: 1.7465 - val_loss: 6.0751 - val_mae: 2.2164\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.4790 - mae: 1.7319 - val_loss: 6.0077 - val_mae: 2.1921\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3958 - mae: 1.7178 - val_loss: 6.0928 - val_mae: 2.2159\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3332 - mae: 1.7046 - val_loss: 6.1561 - val_mae: 2.2250\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.2690 - mae: 1.6933 - val_loss: 6.1648 - val_mae: 2.2208\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1932 - mae: 1.6757 - val_loss: 6.0929 - val_mae: 2.2090\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.1449 - mae: 1.6699 - val_loss: 5.9583 - val_mae: 2.1723\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.1346 - mae: 1.6709 - val_loss: 5.6871 - val_mae: 2.1410\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0579 - mae: 1.6532 - val_loss: 5.3711 - val_mae: 2.0864\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0025 - mae: 1.6487 - val_loss: 5.1862 - val_mae: 2.0344\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.8863 - mae: 1.6168 - val_loss: 5.5480 - val_mae: 2.0452\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.9094 - mae: 1.6218 - val_loss: 5.7213 - val_mae: 2.0490\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8607 - mae: 1.6096 - val_loss: 5.2353 - val_mae: 1.9865\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7424 - mae: 1.5772 - val_loss: 5.1482 - val_mae: 2.0340\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.7498 - mae: 1.5881 - val_loss: 5.0896 - val_mae: 2.0366\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.6886 - mae: 1.5759 - val_loss: 5.2883 - val_mae: 2.0466\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.6324 - mae: 1.5625 - val_loss: 5.2854 - val_mae: 1.9913\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5911 - mae: 1.5537 - val_loss: 5.4690 - val_mae: 1.9891\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5338 - mae: 1.5376 - val_loss: 5.5048 - val_mae: 2.0053\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4994 - mae: 1.5359 - val_loss: 5.3844 - val_mae: 2.0195\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5243 - mae: 1.5313 - val_loss: 6.0457 - val_mae: 2.1478\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.4873 - mae: 1.5329 - val_loss: 5.5323 - val_mae: 2.0928\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3785 - mae: 1.5258 - val_loss: 5.0410 - val_mae: 1.9707\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3280 - mae: 1.5189 - val_loss: 4.8424 - val_mae: 1.8864\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3110 - mae: 1.5109 - val_loss: 4.6213 - val_mae: 1.8187\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.3136 - mae: 1.5207 - val_loss: 4.6626 - val_mae: 1.8645\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.1868 - mae: 1.4848 - val_loss: 5.0730 - val_mae: 1.9275\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1723 - mae: 1.4750 - val_loss: 5.5131 - val_mae: 1.9968\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1410 - mae: 1.4643 - val_loss: 5.1457 - val_mae: 1.9612\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.1005 - mae: 1.4554 - val_loss: 5.1039 - val_mae: 1.9510\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0665 - mae: 1.4465 - val_loss: 4.8786 - val_mae: 1.9098\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0041 - mae: 1.4387 - val_loss: 4.7225 - val_mae: 1.8992\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9786 - mae: 1.4420 - val_loss: 4.8669 - val_mae: 1.9217\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.9567 - mae: 1.4414 - val_loss: 4.9475 - val_mae: 1.8990\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.9502 - mae: 1.4346 - val_loss: 4.9882 - val_mae: 1.9022\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9198 - mae: 1.4249 - val_loss: 4.8217 - val_mae: 1.8736\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9555 - mae: 1.4420 - val_loss: 4.5641 - val_mae: 1.8122\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.8855 - mae: 1.4260 - val_loss: 4.6780 - val_mae: 1.8437\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8228 - mae: 1.3947 - val_loss: 4.6980 - val_mae: 1.8793\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 3.8012 - mae: 1.3886 - val_loss: 5.0501 - val_mae: 1.9239\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.7641 - mae: 1.3904 - val_loss: 4.7206 - val_mae: 1.8840\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.7302 - mae: 1.3908 - val_loss: 4.7297 - val_mae: 1.9110\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6910 - mae: 1.3817 - val_loss: 4.8346 - val_mae: 1.9242\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.7056 - mae: 1.3788 - val_loss: 4.8414 - val_mae: 1.9497\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.7422 - mae: 1.3793 - val_loss: 4.9339 - val_mae: 1.9354\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.7039 - mae: 1.3889 - val_loss: 4.9895 - val_mae: 1.9631\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.7159 - mae: 1.3947 - val_loss: 5.5795 - val_mae: 2.0464\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.7735 - mae: 1.4026 - val_loss: 5.5741 - val_mae: 2.0341\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6590 - mae: 1.3862 - val_loss: 4.9712 - val_mae: 1.8936\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 3.6294 - mae: 1.3815 - val_loss: 4.8034 - val_mae: 1.8598\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5649 - mae: 1.3584 - val_loss: 4.5063 - val_mae: 1.8462\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5476 - mae: 1.3414 - val_loss: 4.5571 - val_mae: 1.8646\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5341 - mae: 1.3411 - val_loss: 4.4439 - val_mae: 1.8643\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.5240 - mae: 1.3463 - val_loss: 4.5898 - val_mae: 1.8751\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.4174 - mae: 1.3193 - val_loss: 4.9630 - val_mae: 1.9286\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 3.4887 - mae: 1.3278 - val_loss: 5.3347 - val_mae: 1.9221\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.4803 - mae: 1.3264 - val_loss: 4.8898 - val_mae: 1.8403\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 3.4077 - mae: 1.3185 - val_loss: 4.3274 - val_mae: 1.7695\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.3756 - mae: 1.3155 - val_loss: 4.6432 - val_mae: 1.8672\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.3341 - mae: 1.2821 - val_loss: 5.0364 - val_mae: 1.9321\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3260 - mae: 1.2678 - val_loss: 4.8875 - val_mae: 1.8965\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.2922 - mae: 1.2640 - val_loss: 4.8485 - val_mae: 1.8946\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3292 - mae: 1.2671 - val_loss: 4.9117 - val_mae: 1.9058\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2956 - mae: 1.2704 - val_loss: 4.5223 - val_mae: 1.8180\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.2324 - mae: 1.2716 - val_loss: 4.7260 - val_mae: 1.7930\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3599 - mae: 1.2945 - val_loss: 5.2501 - val_mae: 1.9160\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.3726 - mae: 1.3000 - val_loss: 4.6965 - val_mae: 1.8048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdLkO9-KZihY"
      },
      "source": [
        "### Evaluate our model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "outputId": "d87cf8d1-86d8-4fed-98cc-8773385961b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN96c-G_ZihY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 7.9996 - mae: 2.1831\n",
            "Mean squared error on test data:  7.999634742736816\n",
            "Mean absolute error on test data:  2.1830618381500244\n"
          ]
        }
      ],
      "source": [
        "mse_nn, mae_nn = model_1.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error on test data: ', mse_nn)\n",
        "print('Mean absolute error on test data: ', mae_nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Pipeline "
      ],
      "metadata": {
        "id": "-nGjVnd0-lNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Step 1: Weights Initialization with count=0\n",
        "*   Step 2: Obtaining Weights and Sending them for Averaging\n",
        "*   Step 3: Waiting for untill we pull the averaged weights\n",
        "*   Step 4: Setting the weights and fitting the model again\n",
        "*   Step 5: Repeat 2 to 4 untill we are satissfied :)\n",
        "\n"
      ],
      "metadata": {
        "id": "TQk0UyNU-sTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickling_weights(filename):\n",
        "  with open(filename, \"rb\") as fp:\n",
        "    ls=pickle.load(fp)\n",
        "  return ls"
      ],
      "metadata": {
        "id": "n1XjreU8Dmvp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls1=unpickling_weights(\"updated_layer_1.json\")\n",
        "np.shape(ls3[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htyzz7JvNdIq",
        "outputId": "e6a381f4-a683-4f95-d94c-94c0970c6efc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows,features=X_test.shape"
      ],
      "metadata": {
        "id": "Eg5OIhtqFHgT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json1=\"updated_layer_1.json\"\n",
        "json2=\"updated_layer_2.json\"\n",
        "json3=\"updated_layer_3.json\"\n",
        "model_name=\"client1_nn.json\""
      ],
      "metadata": {
        "id": "lIevBz8RIgPd"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model,history,mse_nn,mae_nn,count=Training_evaluating(X_train,y_train,X_test,y_test,count,features=13,json1=\"updated_layer_1.json\",json2=\"updated_layer_2.json\",json3=\"updated_layer_3.json\",model_name=\"client1_nn.json\",weight_file_name=\"client1_nn.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvT6qNFxLB8y",
        "outputId": "342dacd8-0e59-4e2a-861c-de6b2f8282c1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 38ms/step - loss: 166.3592 - mae: 12.1154 - val_loss: 108.7497 - val_mae: 10.0384\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 111.5673 - mae: 9.8004 - val_loss: 67.3409 - val_mae: 7.8928\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 68.9261 - mae: 7.4042 - val_loss: 35.6647 - val_mae: 5.6019\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 39.3385 - mae: 5.1413 - val_loss: 16.8307 - val_mae: 3.4519\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 24.3798 - mae: 3.8112 - val_loss: 9.3935 - val_mae: 2.5385\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 18.8991 - mae: 3.3764 - val_loss: 7.1262 - val_mae: 2.0991\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 16.7051 - mae: 3.1992 - val_loss: 5.7441 - val_mae: 1.6122\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.0291 - mae: 2.9602 - val_loss: 5.6171 - val_mae: 1.7964\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.8210 - mae: 2.7892 - val_loss: 6.1415 - val_mae: 1.9365\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.0829 - mae: 2.6902 - val_loss: 6.3457 - val_mae: 2.0009\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.1307 - mae: 2.5828 - val_loss: 6.2156 - val_mae: 2.0434\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.2354 - mae: 2.4744 - val_loss: 6.1765 - val_mae: 2.1027\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.5906 - mae: 2.3935 - val_loss: 6.2647 - val_mae: 2.1831\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.1769 - mae: 2.3302 - val_loss: 6.3882 - val_mae: 2.2627\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.7882 - mae: 2.2680 - val_loss: 6.6620 - val_mae: 2.3349\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.3280 - mae: 2.2042 - val_loss: 6.8549 - val_mae: 2.3561\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.0272 - mae: 2.1674 - val_loss: 6.9438 - val_mae: 2.3483\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.8099 - mae: 2.1417 - val_loss: 6.8619 - val_mae: 2.3415\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.4983 - mae: 2.0869 - val_loss: 6.9380 - val_mae: 2.3722\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.2611 - mae: 2.0379 - val_loss: 6.8022 - val_mae: 2.3725\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.0896 - mae: 2.0083 - val_loss: 6.8873 - val_mae: 2.3963\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9192 - mae: 1.9849 - val_loss: 6.6652 - val_mae: 2.3645\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.7572 - mae: 1.9536 - val_loss: 6.4503 - val_mae: 2.3339\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.5736 - mae: 1.9272 - val_loss: 5.9344 - val_mae: 2.2394\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.5490 - mae: 1.9278 - val_loss: 5.7709 - val_mae: 2.2081\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3857 - mae: 1.9048 - val_loss: 5.9662 - val_mae: 2.2320\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1655 - mae: 1.8743 - val_loss: 6.3877 - val_mae: 2.2866\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1185 - mae: 1.8608 - val_loss: 6.5867 - val_mae: 2.3125\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.0195 - mae: 1.8442 - val_loss: 6.3169 - val_mae: 2.2863\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.9119 - mae: 1.8136 - val_loss: 5.9630 - val_mae: 2.2177\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.7986 - mae: 1.7893 - val_loss: 5.6893 - val_mae: 2.1656\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6813 - mae: 1.7758 - val_loss: 5.6915 - val_mae: 2.1586\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6286 - mae: 1.7672 - val_loss: 5.7831 - val_mae: 2.1723\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.5110 - mae: 1.7433 - val_loss: 5.7125 - val_mae: 2.1781\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4141 - mae: 1.7283 - val_loss: 5.7036 - val_mae: 2.1699\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3555 - mae: 1.7158 - val_loss: 5.5978 - val_mae: 2.1447\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2950 - mae: 1.7013 - val_loss: 5.4756 - val_mae: 2.1287\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2122 - mae: 1.6881 - val_loss: 5.4635 - val_mae: 2.1186\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1626 - mae: 1.6796 - val_loss: 5.4251 - val_mae: 2.0758\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1329 - mae: 1.6761 - val_loss: 5.3422 - val_mae: 2.0273\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0655 - mae: 1.6712 - val_loss: 5.9095 - val_mae: 2.0967\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.0626 - mae: 1.6729 - val_loss: 5.7276 - val_mae: 2.0838\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.0936 - mae: 1.6691 - val_loss: 5.4614 - val_mae: 2.0890\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0442 - mae: 1.6528 - val_loss: 5.6681 - val_mae: 2.1588\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 1s 9ms/step - loss: 4.8555 - mae: 1.6043 - val_loss: 5.6330 - val_mae: 2.1457\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8070 - mae: 1.5957 - val_loss: 5.1068 - val_mae: 2.0185\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7506 - mae: 1.5890 - val_loss: 5.1135 - val_mae: 1.9989\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.6279 - mae: 1.5641 - val_loss: 5.1499 - val_mae: 1.9450\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6140 - mae: 1.5678 - val_loss: 5.1890 - val_mae: 1.9278\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5700 - mae: 1.5556 - val_loss: 4.9576 - val_mae: 1.8966\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5120 - mae: 1.5404 - val_loss: 4.8221 - val_mae: 1.9015\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4819 - mae: 1.5367 - val_loss: 4.7486 - val_mae: 1.8878\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4317 - mae: 1.5312 - val_loss: 5.2004 - val_mae: 1.9447\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4490 - mae: 1.5287 - val_loss: 5.4563 - val_mae: 1.9972\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3637 - mae: 1.5089 - val_loss: 5.1995 - val_mae: 1.9869\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3317 - mae: 1.5077 - val_loss: 4.8864 - val_mae: 1.9975\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4521 - mae: 1.5396 - val_loss: 4.4822 - val_mae: 1.9186\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3717 - mae: 1.5077 - val_loss: 4.7675 - val_mae: 1.9295\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2533 - mae: 1.4845 - val_loss: 5.2030 - val_mae: 2.0037\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.1830 - mae: 1.4689 - val_loss: 5.5059 - val_mae: 2.0558\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.2551 - mae: 1.4854 - val_loss: 5.7999 - val_mae: 2.0874\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1882 - mae: 1.4783 - val_loss: 5.4734 - val_mae: 2.0163\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0473 - mae: 1.4501 - val_loss: 4.9941 - val_mae: 1.9676\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0244 - mae: 1.4467 - val_loss: 4.5947 - val_mae: 1.8814\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0491 - mae: 1.4605 - val_loss: 4.7607 - val_mae: 1.9129\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.9538 - mae: 1.4311 - val_loss: 5.0196 - val_mae: 1.9649\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0514 - mae: 1.4560 - val_loss: 4.7623 - val_mae: 1.9256\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9963 - mae: 1.4464 - val_loss: 4.5148 - val_mae: 1.8805\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8998 - mae: 1.4424 - val_loss: 4.8926 - val_mae: 1.9178\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8618 - mae: 1.4234 - val_loss: 5.4165 - val_mae: 2.0026\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9050 - mae: 1.4187 - val_loss: 5.6789 - val_mae: 2.0573\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8790 - mae: 1.4194 - val_loss: 5.3295 - val_mae: 2.0395\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8635 - mae: 1.4269 - val_loss: 4.9958 - val_mae: 1.9766\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.7830 - mae: 1.4019 - val_loss: 4.9111 - val_mae: 1.9190\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.7661 - mae: 1.4026 - val_loss: 4.2883 - val_mae: 1.7891\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.7612 - mae: 1.4054 - val_loss: 4.3668 - val_mae: 1.8140\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6957 - mae: 1.3714 - val_loss: 4.7859 - val_mae: 1.8875\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6609 - mae: 1.3528 - val_loss: 4.3506 - val_mae: 1.8150\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6615 - mae: 1.3726 - val_loss: 4.1451 - val_mae: 1.8187\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6232 - mae: 1.3701 - val_loss: 4.4584 - val_mae: 1.8687\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5874 - mae: 1.3573 - val_loss: 4.8130 - val_mae: 1.8959\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5623 - mae: 1.3496 - val_loss: 4.9324 - val_mae: 1.9014\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5485 - mae: 1.3474 - val_loss: 4.8499 - val_mae: 1.8969\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5380 - mae: 1.3459 - val_loss: 4.9345 - val_mae: 1.9171\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4912 - mae: 1.3381 - val_loss: 4.7128 - val_mae: 1.8962\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4686 - mae: 1.3373 - val_loss: 4.7138 - val_mae: 1.9124\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.5976 - mae: 1.3528 - val_loss: 5.2561 - val_mae: 1.9500\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.6711 - mae: 1.3807 - val_loss: 4.4136 - val_mae: 1.8375\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6067 - mae: 1.3688 - val_loss: 4.0681 - val_mae: 1.7830\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.4352 - mae: 1.3321 - val_loss: 4.5970 - val_mae: 1.8374\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3662 - mae: 1.2934 - val_loss: 4.7086 - val_mae: 1.8352\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.4099 - mae: 1.3064 - val_loss: 4.3396 - val_mae: 1.7592\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 1s 9ms/step - loss: 3.4510 - mae: 1.3287 - val_loss: 4.1234 - val_mae: 1.7216\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.4036 - mae: 1.3194 - val_loss: 4.3831 - val_mae: 1.7921\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3033 - mae: 1.2834 - val_loss: 4.6341 - val_mae: 1.8447\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3342 - mae: 1.2909 - val_loss: 4.9200 - val_mae: 1.9113\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.2786 - mae: 1.2922 - val_loss: 4.7307 - val_mae: 1.8956\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2700 - mae: 1.3143 - val_loss: 4.4981 - val_mae: 1.8721\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3509 - mae: 1.3361 - val_loss: 4.7166 - val_mae: 1.8816\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2267 - mae: 1.2972 - val_loss: 4.8623 - val_mae: 1.8875\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 8.4806 - mae: 2.2440\n",
            "Mean squared error on test data:  8.480643272399902\n",
            "Mean absolute error on test data:  2.2440264225006104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Give value of count carefuully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTpWBMATOwNz",
        "outputId": "e7e1945a-90ff-4b16-edbd-9e783311b2f3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give value of count carefuully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Training_evaluating(X_train,y_train,X_test,y_test,count,features,json1=None,json2=None,json3=None,model_name=None,weight_file_name=None):\n",
        "\n",
        "    if count==0:\n",
        "      model = Sequential()\n",
        "      model.add(Dense(128, input_shape=(features, ), activation='relu', name='dense_1'))\n",
        "      model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "      model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "      model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "      model.summary()\n",
        "\n",
        "      history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
        "\n",
        "      mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "      print('Mean squared error on test data: ', mse_nn)\n",
        "      print('Mean absolute error on test data: ', mae_nn)\n",
        "\n",
        "      sending_models_and_weights(model,model_name,weight_file_name)\n",
        "      count=1\n",
        "    else:\n",
        "      ls1=unpickling_weights(json1)      \n",
        "      ls2=unpickling_weights(json2)      \n",
        "      ls3=unpickling_weights(json3)\n",
        "\n",
        "      # Creating a new model from the saved JSON file\n",
        "      # read the model from the JSOn file\n",
        "      with open(model_name, 'r') as json_file:\n",
        "        json_savedModel= json_file.read()\n",
        "      #json_savedModel\n",
        "      #load the model architecture \n",
        "      model = tf.keras.models.model_from_json(json_savedModel)\n",
        "      model.summary()\n",
        "      model.layers[0].set_weights(ls1)\n",
        "      model.layers[1].set_weights(ls2)\n",
        "      model.layers[2].set_weights(ls3)   \n",
        "      \n",
        "      model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "      history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
        "\n",
        "      mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "      print('Mean squared error on test data: ', mse_nn)\n",
        "      print('Mean absolute error on test data: ', mae_nn)\n",
        "      count+=1\n",
        "      \n",
        "    return model,history,mse_nn,mae_nn,count\n",
        "\n",
        "def sending_models_and_weights(model,model_name,weight_file_name):\n",
        "    \n",
        "   \n",
        "    # serialize model to json\n",
        "    json_model = model.to_json()\n",
        "    #json_model\n",
        "    #save the model architecture to JSON file\n",
        "    with open(model_name, 'w') as json_file:\n",
        "        json_file.write(json_model)\n",
        "\n",
        "    model.save_weights(weight_file_name)\n",
        "    "
      ],
      "metadata": {
        "id": "C0rLHEXY-kni"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Training_evaluating(X_train,y_train,X_test,y_test,count,features,json1=None,json2=None,json3=None,model_name=None,weight_file_name=None):\n",
        "\n",
        "    if count==0:\n",
        "      model = Sequential()\n",
        "      model.add(Dense(128, input_shape=(features, ), activation='relu', name='dense_1'))\n",
        "      model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "      model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "      model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "      model.summary()\n",
        "\n",
        "      history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
        "\n",
        "      mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "      print('Mean squared error on test data: ', mse_nn)\n",
        "      print('Mean absolute error on test data: ', mae_nn)\n",
        "\n",
        "      sending_models_and_weights(model,model_name,weight_file_name)\n",
        "      count=1\n",
        "    else:\n",
        "      ls1=unpickling_weights(json1)      \n",
        "      ls2=unpickling_weights(json2)      \n",
        "      ls3=unpickling_weights(json3)\n",
        "\n",
        "      # Creating a new model from the saved JSON file\n",
        "      # read the model from the JSOn file\n",
        "      with open(model_name, 'r') as json_file:\n",
        "        json_savedModel= json_file.read()\n",
        "      #json_savedModel\n",
        "      #load the model architecture \n",
        "      model_1 = tf.keras.models.model_from_json(json_savedModel)\n",
        "      model_1.summary()\n",
        "      model_1.layers[0].set_weights(ls1)\n",
        "      model_1.layers[1].set_weights(ls2)\n",
        "      model_1.layers[2].set_weights(ls3)   \n",
        "      \n",
        "      \n",
        "\n",
        "        \n",
        "      history = model_1.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
        "\n",
        "      mse_nn, mae_nn = model_1.evaluate(X_test, y_test)\n",
        "\n",
        "      print('Mean squared error on test data: ', mse_nn)\n",
        "      print('Mean absolute error on test data: ', mae_nn)\n",
        "      count+=1\n",
        "      sending_models_and_weights(model_1,model_name,weight_file_name)\n",
        "      \n",
        "    return model_1,history,mse_nn,mae_nn,count\n",
        "\n",
        "def sending_models_and_weights(model,model_name,weight_file_name):\n",
        "    \n",
        "   \n",
        "    # serialize model to json\n",
        "    json_model = model.to_json()\n",
        "    #json_model\n",
        "    #save the model architecture to JSON file\n",
        "    with open(model_name, 'w') as json_file:\n",
        "        json_file.write(json_model)\n",
        "\n",
        "    model.save_weights(weight_file_name)\n",
        "    "
      ],
      "metadata": {
        "id": "d1NbB8t_Pfo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func(a,b,cond=None):\n",
        "  print(cond)\n",
        "  return a+b\n",
        "func(2,3,19)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEMt-F1WJaBk",
        "outputId": "fd8d781f-f610-49f8-99d5-fef74b7627c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N3TVxERmG1h0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bresan_env",
      "language": "python",
      "name": "bresan_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "client1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "On8p6XM9y8Il",
        "sCJSkiWJUcwZ",
        "TZQLkkCeYqNg",
        "GdLkO9-KZihY"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}